@article{zhangkun1994,
  author     = {张昆 and 冯立群 and 余昌钰 and others},
  title      = {机器人柔性手腕的球面齿轮设计研究},
  journal    = {清华大学学报: 自然科学版},
  volume     = {34},
  number     = {2},
  pages      = {1--7},
  year       = {1994},
  key        = {zhang1 kun1},
}

@book{zhukezhen1973,
  author     = {竺可桢},
  title      = {物理学论},
  address    = {北京},
  publisher  = {科学出版社},
  year       = {1973},
  pages      = {56--60},
  key        = {zhu2 ke3 zhen1},
}

@inproceedings{dupont1974bone,
  author     = {Dupont, B},
  title      = {Bone marrow transplantation in severe combined immunodeficiency with an unrelated MLC compatible donor},
  editor     = {White, H J and Smith, R},
  booktitle  = {Proceedings of the third annual meeting of the International Society for Experimental Hematology},
  address    = {Houston},
  publisher  = {International Society for Experimental Hematology},
  year       = {1974},
  pages      = {44--46},
}

@mastersthesis{zhengkaiqing1987,
  author     = {郑开青},
  title      = {通讯系统模拟及软件},
  address    = {北京},
  school     = {清华大学无线电系},
  year       = {1987},
  key        = {zheng4 kai1 qing1},
}

@patent{jiangxizhou1980,
  author     = {姜锡洲},
  title      = {一种温热外敷药制备方案},
  address    = {中国},
  number     = {88105607.3},
  year       = {1980},
  date       = {1980-07-26},
  key        = {jiang1 xi1 zhou1},
}

@standard{jianduju1994,
  author     = {中华人民共和国国家技术监督局},
  title      = {GB3100-3102. 中华人民共和国国家标准-量与单位},
  address    = {北京},
  publisher  = {中国标准出版社},
  year       = {1994},
  key        = {zhong1 hua2 ren2 min2 gong4 he2 guo2},
}

@article{merkt1995rotational,
  author     = {Merkt, Fr{\'e}d{\'e}ric and Mackenzie, S R and Softley, Timothy P},
  title      = {Rotational Autoionization Dynamics in High Rydberg States of Nitrogen},
  journal    = {J Chem Phys},
  year       = {1995},
  volume     = {103},
  pages      = {4509--4518},
}

@article{mellinger1996laser,
  author     = {Mellinger, A and Vidal, C R and Jungen, {Ch}},
  title      = {Laser reduced fluorescence study of the carbon monoxide nd triplet Rydberg series - Experimental results and multichannel quantum defect analysis},
  journal    = {J Chem Phys},
  year       = {1996},
  volume     = {104},
  pages      = {8913--8921},
}

@article{bixon1996dynamics,
  author     = {Bixon, M and Jortner, Joshua},
  title      = {The dynamics of predissociating high {Rydberg} states of {NO}},
  journal    = {J Chem Phys},
  year       = {1996},
  volume     = {105},
  pages      = {1363--1382},
}

@article{mahui1995,
  author     = {马辉 and 李俭 and 刘耀明 and others},
  title      = {利用 {REMPI} 方法测量 {BaF} 高里德堡系列光谱},
  journal    = {化学物理学报},
  year       = {1995},
  volume     = {8},
  pages      = {308--311},
  key        = {ma3 hui1},
}

@article{carlson1981two,
  author     = {Carlson, N W and Taylor, A J and Jones, K M and Schawlow, A L},
  title      = {Two-step polarization-labeling spectroscopy of excited states of {Na2}},
  journal    = {Phys Rev A},
  year       = {1981},
  volume     = {24},
  pages      = {822--834},
}

@article{taylor1983scanning,
  author     = {Taylor, A J and Jones, K M and Schawlow, A L},
  title      = {Scanning pulsed-polarization spectrometer applied to {Na2}},
  journal    = {J Opt Soc Am},
  year       = {1983},
  volume     = {73},
  pages      = {994--998},
}

@article{taylor1981study,
  author     = {Taylor, A J and Jones, K M and Schawlow, A L},
  title      = {A study of the excited {1$\Sigma$g+} states in {Na2}},
  journal    = {Opt Commun},
  year       = {1981},
  volume     = {39},
  pages      = {47--50},
}

@article{shimizu1983laser,
  author     = {Shimizu, Kazuko and Shimizu, Fujio},
  title      = {Laser induced fluorescence spectra of the a {3$\Pi$u--X 1$\Sigma$g+} band of {Na2} by molecular beam},
  journal    = {J Chem Phys},
  year       = {1983},
  volume     = {78},
  pages      = {1126--1131},
}

@article{atkinson1982experimental,
  author     = {Atkinson, J B and Becker, J and Demtr{\"o}der, W},
  title      = {Experimental observation of the a {3$\Pi$u} state of {Na2}},
  journal    = {Chem Phys Lett},
  year       = {1982},
  volume     = {87},
  pages      = {92--97},
}

@article{kusch1975perturbations,
  author     = {Kusch, P and Hessel, M M},
  title      = {Perturbations in the A {1$\Sigma$u+} state of {Na2}},
  journal    = {J Chem Phys},
  year       = {1975},
  volume     = {63},
  pages      = {4087--4088},
}

@book{guangxi1993,
  author     = {广西壮族自治区林业厅},
  title      = {广西自然保护区},
  address    = {北京},
  publisher  = {中国林业出版社},
  year       = {1993},
  key        = {guang3 xi1 zhuang4 zu2 zi4 zhi4 qu1},
}

@book{huosini1989guwu,
  author     = {霍斯尼},
  title      = {谷物科学与工艺学原理},
  translator = {李庆龙},
  edition    = {2},
  address    = {北京},
  publisher  = {中国食品出版社},
  year       = {1989},
  pages      = {15--20},
  key        = {huo4 si1 ni2},
}

@book{wangfuzhi1865songlun,
  author     = {王夫之},
  title      = {宋论},
  edition    = {刻本},
  address    = {金陵},
  publisher  = {曾氏},
  year       = {1865（清同治四年）},
  key        = {wang2 fu1 zhi1},
}

@book{zhaoyaodong1998xinshidai,
  author     = {赵耀东},
  title      = {新时代的工业工程师},
  address    = {台北},
  publisher  = {天下文化出版社},
  year       = {1998},
  urldate    = {1998-09-26},
  url        = {http://www.ie.nthu.edu.tw/info/ie.newie.htm},
  key        = {zhao4 yao4 dong1},
}

@standard{biaozhunhua2002tushu,
  author     = {全国信息与文献工作标准化技术委员会出版物格式分委员会},
  title      = {GB/T 12450-2001 图书书名页},
  address    = {北京},
  publisher  = {中国标准出版社},
  year       = {2002},
  pages      = {1},
  key        = {quan2 guo2 xin4 xi1},
}

@book{chubanzhuanye2004,
  author     = {全国出版专业职业资格考试办公室},
  title      = {全国出版专业职业资格考试辅导教材: 出版专业理论与实务•中级},
  edition    = {2014},
  address    = {上海},
  publisher  = {上海辞书出版社},
  year       = {2004},
  pages      = {299--307},
  key        = {quan2 guo2 chu1 ban3 ye4},
}

@techreport{who1970factors,
  author     = {{World Health Organization}},
  title      = {Factors Regulating the Immune Response: Report of {WHO Scientific Group}},
  address    = {Geneva},
  publisher  = {WHO},
  year       = {1970},
}

@book{peebles2001probability,
  author     = {Peebles, Jr, Peyton Z.},
  title      = {Probability, Random Variables, and Random Signal Principles},
  edition    = {4},
  address    = {New York},
  publisher  = {McGraw Hill},
  year       = {2001},
}

@incollection{baishunong1998zhiwu,
  author     = {白书农},
  title      = {植物开花研究},
  editor     = {李承森},
  booktitle  = {植物科学进展},
  address    = {北京},
  publisher  = {高等教育出版社},
  year       = {1998},
  pages      = {146--163},
  key        = {bai2 shu1 nong2},
}

@incollection{weinstein1974pathogenic,
  author     = {Weinstein, L and Swertz, M N},
  title      = {Pathogenic Properties of Invading Microorganism},
  editor     = {Sodeman, Jr, William A and Sodeman, William A},
  booktitle  = {Pathologic physiology: mechanisms of disease},
  address    = {Philadelphia},
  publisher  = {Saunders},
  year       = {1974},
  pages      = {745--772},
}

@inproceedings{hanjiren1985lun,
  author     = {韩吉人},
  title      = {论职工教育的特点},
  editor     = {中国职工教育研究会},
  booktitle  = {职工教育研究论文集},
  address    = {北京},
  publisher  = {人民教育出版社},
  year       = {1985},
  pages      = {90--99},
  key        = {han2 ji2 ren2},
}

@periodical{dizhi1936dizhi,
  author     = {中国地质学会},
  title      = {地质评论},
  year       = {1936},
  volume     = {1},
  number     = {1},
  address    = {北京},
  publisher  = {地质出版社},
  key        = {zhong1 guo2 di4 zhi3 xue2 hui4},
}

@periodical{tushuguan1957tushuguanxue,
  author     = {中国图书馆学会},
  title      = {图书馆学通讯},
  year       = {1957/1990},
  number     = {1--4},
  address    = {北京},
  publisher  = {北京图书馆},
  key        = {zhong1 guo2 tu2 shu1 guan3 xue2 hui4},
}

@periodical{aaas1883science,
  author     = {{American Association for the Advancement of Science}},
  title      = {Science},
  year       = {1883},
  volume     = {1},
  number     = {1},
  address    = {Washington, D.C.},
  publisher  = {American Association for the Advancement of Science},
}

@newspaper{fugang2000fengsha,
  author     = {傅刚 and 赵承 and 李佳路},
  title      = {大风沙过后的思考},
  journal    = {北京青年报},
  year       = {2000},
  date       = {2000-04-12},
  number     = {14},
  urldate    = {2002-03-06},
  url        = {http://www.bjyouth.com.cn/Bqb/20000412/B/4216%5ED0412B1401.htm},
  key        = {fu4 gang1},
}

@online{xiaoyu2001chubanye,
  author     = {萧钰},
  title      = {出版业信息化迈入快车道},
  year       = {2001},
  date       = {2001-12-19},
  urldate    = {2002-04-15},
  url        = {http://www.creader.com/news/20011219/200112190019.htm},
  key        = {xiao1 yu4},
}

@online{oclc2000about,
  author     = {{Online Computer Library Center, Inc}},
  title      = {About {OCLC}: History of Cooperation},
  year       = {2000},
  urldate    = {2000-01-08},
  url        = {http://www.oclc.org/about/cooperation.en.htm},
}

@software{scitor2000project,
  author     = {{Scitor Corporation}},
  title      = {Project scheduler},
  address    = {Sunnyvale, Calif.},
  publisher  = {Scitor Corporation},
  year       = {1983},
  medium     = {DK},
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{bemis2013basic,
  title={Basic linguistic composition recruits the left anterior temporal lobe and left angular gyrus during both listening and reading},
  author={Bemis, Douglas K and Pylkk{\"a}nen, Liina},
  journal={Cerebral cortex},
  volume={23},
  number={8},
  pages={1859--1873},
  year={2013},
  publisher={Oxford University Press}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
    booktitle = {Proceedings of the European Conference on Computer Vision},
    organization = {Springer},
  pages={181--196},
  year={2018}
}

@inproceedings{chen2020simple,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@preprint{MoBY,
      title={Self-Supervised Learning with Swin Transformers}, 
      author={Zhenda Xie and Yutong Lin and Zhuliang Yao and Zheng Zhang and Qi Dai and Yue Cao and Han Hu},
      year={2021},
      eprint={2105.04553},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2105.04553}, 
}

@article{wang2019learningSketch,
    title={Learning Robust Global Representations by Penalizing Local Predictive Power},
    author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
    journal={Advances in Neural Information Processing Systems},
    volume={32},
    year={2019}
}

@article{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

 @preprint{schuhmann2021laion400m,
      title={LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs}, 
      author={Christoph Schuhmann and Richard Vencu and Romain Beaumont and Robert Kaczmarczyk and Clayton Mullis and Aarush Katta and Theo Coombes and Jenia Jitsev and Aran Komatsuzaki},
      year={2021},
      eprint={2111.02114},
      archivePrefix={arXiv},
          url={https://arxiv.org/abs/2111.02114}
}

@inproceedings{cubuk2020randaugment,
  title={RandAugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={702--703},
  year={2020}
}

@inproceedings{huang2016deep,
 author = {Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
 booktitle = {Proceedings of the European Conference on Computer Vision},
 organization = {Springer},
 pages = {646--661},
 title = {Deep Networks with Stochastic Depth},
 year = {2016}
}

@inproceedings{Swin,
    title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@preprint{liu2019roberta,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  eprint={1907.11692},
  archiveprefix={arXiv},
  url={https://arxiv.org/abs/1907.11692},
  year={2019}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{desai2021virtex,
  title={Virtex: Learning visual representations from textual annotations},
  author={Desai, Karan and Johnson, Justin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11162--11173},
  year={2021}
}

@inproceedings{sariyildiz2020learning,
  title={Learning visual representations with caption annotations},
  author={Sariyildiz, Mert Bulent and Perez, Julien and Larlus, Diane},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={153--170},
  year={2020},
  organization={Springer}
}

@inproceedings{gupta2019lvis,
  title={LVIS: A dataset for large vocabulary instance segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5356--5364},
  year={2019}
}

@preprint{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archiveprefix={arXiv},
      url={https://arxiv.org/abs/2303.08774},
}

@inproceedings{elmo,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    year = "2018",
    publisher = "Association for Computational Linguistics",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals."
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{devise,
 author = {Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Ranzato, Marc\textquotesingle Aurelio and Mikolov, Tomas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {DeViSE: A Deep Visual-Semantic Embedding Model},
 url = {https://proceedings.neurips.cc/paper_files/paper/2013/file/7cce53cf90577442771720a370c3c723-Paper.pdf},
 volume = {26},
 year = {2013}
}

@INPROCEEDINGS{imagnettransfer,
  title={Do Better ImageNet Models Transfer Better?}, 
  year={2019},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V.},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  pages={2656-2666},
}

@preprint{dsv3,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI and Aixin Liu and Bei Feng and Bing Xue and Bingxuan Wang and Bochao Wu and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Daya Guo and Dejian Yang and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Haowei Zhang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Li and Hui Qu and J. L. Cai and Jian Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li and Jiawei Wang and Jin Chen and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and Junxiao Song and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Lei Xu and Leyi Xia and Liang Zhao and Litong Wang and Liyue Zhang and Meng Li and Miaojun Wang and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Mingming Li and Ning Tian and Panpan Huang and Peiyi Wang and Peng Zhang and Qiancheng Wang and Qihao Zhu and Qinyu Chen and Qiushi Du and R. J. Chen and R. L. Jin and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and Runxin Xu and Ruoyu Zhang and Ruyi Chen and S. S. Li and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shaoqing Wu and Shengfeng Ye and Shengfeng Ye and Shirong Ma and Shiyu Wang and Shuang Zhou and Shuiping Yu and Shunfeng Zhou and Shuting Pan and T. Wang and Tao Yun and Tian Pei and Tianyu Sun and W. L. Xiao and Wangding Zeng and Wanjia Zhao and Wei An and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and X. Q. Li and Xiangyue Jin and Xianzu Wang and Xiao Bi and Xiaodong Liu and Xiaohan Wang and Xiaojin Shen and Xiaokang Chen and Xiaokang Zhang and Xiaosha Chen and Xiaotao Nie and Xiaowen Sun and Xiaoxiang Wang and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xingkai Yu and Xinnan Song and Xinxia Shan and Xinyi Zhou and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and Y. K. Li and Y. Q. Wang and Y. X. Wei and Y. X. Zhu and Yang Zhang and Yanhong Xu and Yanhong Xu and Yanping Huang and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Li and Yaohui Wang and Yi Yu and Yi Zheng and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Ying Tang and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yu Wu and Yuan Ou and Yuchen Zhu and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yukun Zha and Yunfan Xiong and Yunxian Ma and Yuting Yan and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Z. F. Wu and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhen Huang and Zhen Zhang and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhibin Gou and Zhicheng Ma and Zhigang Yan and Zhihong Shao and Zhipeng Xu and Zhiyu Wu and Zhongyu Zhang and Zhuoshu Li and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Ziyi Gao and Zizheng Pan},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}

@inproceedings{nguyen2010cosine,
  title={Cosine similarity metric learning for face verification},
  author={Nguyen, Hieu V and Bai, Li},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={709--720},
  year={2010},
  organization={Springer}
}

@article{palm,
author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sashank and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
title = {PaLM: scaling language modeling with pathways},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540- billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {240},
numpages = {113},
keywords = {large language models, few-shot learning, natural language processing, scalable deep learning}
}

@inproceedings{
dVAE,
title={Discrete Variational Autoencoders},
author={Jason Tyler Rolfe},
booktitle={International Conference on Learning Representations},
year={2017},
}



@InProceedings{ImageGPT,
  title = 	 {Generative Pretraining From Pixels},
  author =       {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {1691--1703},
  year = 	 {2020},
  organization =    {PMLR},
}

@article{chen2018adversarial,
  title={Adversarial distillation for efficient recommendation with external knowledge},
  author={Chen, Xu and Zhang, Yongfeng and Xu, Hongteng and Qin, Zheng and Zha, Hongyuan},
  journal={ACM Transactions on Information Systems},
  volume={37},
  number={1},
  pages={1--28},
  year={2018},
}

@InProceedings{TinyCLIP,
    author    = {Wu, Kan and Peng, Houwen and Zhou, Zhenghong and Xiao, Bin and Liu, Mengchen and Yuan, Lu and Xuan, Hong and Valenzuela, Michael and Chen, Xi (Stephen) and Wang, Xinggang and Chao, Hongyang and Hu, Han},
    title     = {TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    month     = {October},
    year      = {2023},
    pages     = {21970-21980}
}

@inproceedings{zhai2019lifelong,
  title={Lifelong gan: Continual learning for conditional image generation},
  author={Zhai, Mengyao and Chen, Lei and Tung, Frederick and He, Jiawei and Nawhal, Megha and Mori, Greg},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2759--2768},
  year={2019}
}

@InProceedings{FLIP,
    author    = {Li, Yanghao and Fan, Haoqi and Hu, Ronghang and Feichtenhofer, Christoph and He, Kaiming},
    title     = {Scaling Language-Image Pre-Training via Masking},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2023},
    pages     = {23390-23400}
}

@article{byol,
 author = {Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
 journal = {Advances in Neural Information Processing Systems},
 title = {Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning},
 volume = {33},
 year = {2020}
}


@InProceedings{moco,
author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
title = {Momentum Contrast for Unsupervised Visual Representation Learning},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages = {9729--9738},
month = {June},
year = {2020}
}

@inproceedings{zsseg,
author = {Xu, Mengde and Zhang, Zheng and Wei, Fangyun and Lin, Yutong and Cao, Yue and Hu, Han and Bai, Xiang},
title = {A Simple Baseline for Open-Vocabulary Semantic Segmentation with Pre-trained Vision-Language Model},
year = {2022},
booktitle = {Proceedings of the European Conference on Computer Vision},
organization = {Springer},
pages = {736–753},
}

@inproceedings{openseg,
author = {Ghiasi, Golnaz and Gu, Xiuye and Cui, Yin and Lin, Tsung-Yi},
title = {Scaling Open-Vocabulary Image Segmentation with Image-Level Labels},
year = {2022},
    booktitle = {Proceedings of the European Conference on Computer Vision},
    organization = {Springer},
pages = {540–557},
}

@inproceedings{mixedtraining,
title={Bootstrap Your Object Detector via Mixed Training},
author={Mengde Xu and Zheng Zhang and Fangyun Wei and Yutong Lin and Yue Cao and Stephen Lin and Han Hu and Xiang Bai},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=B9yXBaZDUxp}
}

@InProceedings{softteacher,
    author    = {Xu, Mengde and Zhang, Zheng and Hu, Han and Wang, Jianfeng and Wang, Lijuan and Wei, Fangyun and Bai, Xiang and Liu, Zicheng},
    title     = {End-to-End Semi-Supervised Object Detection With Soft Teacher},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {3060-3069}
}

@preprint{yalniz2019billionscalesemisupervisedlearningimage,
      title={Billion-scale semi-supervised learning for image classification}, 
      author={I. Zeki Yalniz and Hervé Jégou and Kan Chen and Manohar Paluri and Dhruv Mahajan},
      year={2019},
      eprint={1905.00546},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1905.00546}, 
}

@article{krizhevsky2012alexnet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in Neural Information Processing Systems},
  pages={1097--1105},
  year={2012}
}

@article{
coatnet,
title={CoAtNet: Marrying Convolution and Attention for All Data Sizes},
author={Zihang Dai and Hanxiao Liu and Quoc V Le and Mingxing Tan},
journal={Advances in Neural Information Processing Systems},
year={2021},
volume={34},
}

@InProceedings{densenet,
  title={Densely Connected Convolutional Networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4700--4708},
  year={2017}
}

@InProceedings{resnet,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages={770--778},
month = {June},
year = {2016}
}

@InProceedings{googlenet,
  author={Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Going deeper with convolutions}, 
  year={2015},
  pages={1-9},
}

@misc{kang2024farvideogenerationworld,
      title={How Far is Video Generation from World Model: A Physical Law Perspective}, 
      author={Bingyi Kang and Yang Yue and Rui Lu and Zhijie Lin and Yang Zhao and Kaixin Wang and Gao Huang and Jiashi Feng},
      year={2024},
      eprint={2411.02385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.02385}, 
}


%%%%% ARXIV 用这个 %%%%%
@preprint{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  year={2018},
  eprint={1807.03748},
  archiveprefix={arXiv},
  url={https://arxiv.org/abs/1807.03748}
}

@inproceedings{imageinwords,
    title = "{I}mage{I}n{W}ords: Unlocking Hyper-Detailed Image Descriptions",
    author = "Garg, Roopal  and
      Burns, Andrea  and
      Karagol Ayan, Burcu  and
      Bitton, Yonatan  and
      Montgomery, Ceslee  and
      Onoe, Yasumasa  and
      Bunner, Andrew  and
      Krishna, Ranjay  and
      Baldridge, Jason Michael  and
      Soricut, Radu",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    year = "2024",
    publisher = "Association for Computational Linguistics",
    pages = "93--127",
}

%%%%%%%%%%%下面这个也可以一样显示
@article{flexcap,
 author = {Dwibedi, Debidatta and Jain, Vidhi and Tompson, Jonathan and Zisserman, Andrew and Aytar, Yusuf},
 journal = {Advances in Neural Information Processing Systems},
 title = {FlexCap: Describe Anything in Images in Controllable Detail},
 volume = {37},
 year = {2024}
}


@article{zhou2019ade,
  title={Semantic understanding of scenes through the ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  journal={International Journal of Computer Vision},
  volume={127},
  pages={302--321},
  year={2019},
  publisher={Springer}
}

@preprint{kay2017kinetics,
      title={The Kinetics Human Action Video Dataset}, 
      author={Will Kay and Joao Carreira and Karen Simonyan and Brian Zhang and Chloe Hillier and Sudheendra Vijayanarasimhan and Fabio Viola and Tim Green and Trevor Back and Paul Natsev and Mustafa Suleyman and Andrew Zisserman},
      year={2017},
      eprint={1705.06950},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1705.06950}, 
}

@inproceedings{wang2018cosface,
  title={Cosface: Large margin cosine loss for deep face recognition},
  author={Wang, Hao and Wang, Yitong and Zhou, Zheng and Ji, Xing and Gong, Dihong and Zhou, Jingchao and Li, Zhifeng and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5265--5274},
  year={2018}
}

@InProceedings{DengArcFace,
author = {Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
title = {ArcFace: Additive Angular Margin Loss for Deep Face Recognition},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
month = {June},
pages = {4690-4699},
year = {2019}
}

@article{cao2020parametric,
  title={Parametric instance classification for unsupervised visual feature learning},
  author={Cao, Yue and Xie, Zhenda and Liu, Bin and Lin, Yutong and Zhang, Zheng and Hu, Han},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{devillers-etal-2021-language,
    title = "Does language help generalization in vision models?",
    author = "Devillers, Benjamin  and
      Choksi, Bhavin  and
      Bielawski, Romain  and
      VanRullen, Rufin",
    editor = "Bisazza, Arianna  and
      Abend, Omri",
    booktitle = "Proceedings of the 25th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.conll-1.13/",
    doi = "10.18653/v1/2021.conll-1.13",
    pages = "171--182",
    abstract = "Vision models trained on multimodal datasets can benefit from the wide availability of large image-caption datasets. A recent model (CLIP) was found to generalize well in zero-shot and transfer learning settings. This could imply that linguistic or {\textquotedblleft}semantic grounding{\textquotedblright} confers additional generalization abilities to the visual feature space. Here, we systematically evaluate various multimodal architectures and vision-only models in terms of unsupervised clustering, few-shot learning, transfer learning and adversarial robustness. In each setting, multimodal training produced no additional generalization capability compared to standard supervised visual training. We conclude that work is still required for semantic grounding to help improve vision models."
}

@inproceedings{sharma-etal-2018-conceptual,
    title = "Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning",
    author = "Sharma, Piyush  and
      Ding, Nan  and
      Goodman, Sebastian  and
      Soricut, Radu",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2018",
    publisher = "Association for Computational Linguistics",
    pages = "2556--2565",
    abstract = "We present a new dataset of image caption annotations, Conceptual Captions, which contains an order of magnitude more images than the MS-COCO dataset (Lin et al., 2014) and represents a wider variety of both images and image caption styles. We achieve this by extracting and filtering image caption annotations from billions of webpages. We also present quantitative evaluations of a number of image captioning models and show that a model architecture based on Inception-ResNetv2 (Szegedy et al., 2016) for image-feature extraction and Transformer (Vaswani et al., 2017) for sequence modeling achieves the best performance when trained on the Conceptual Captions dataset."
}

@inproceedings{dai-etal-2022-knowledge,
    title = "Knowledge Neurons in Pretrained Transformers",
    author = "Dai, Damai  and
      Dong, Li  and
      Hao, Yaru  and
      Sui, Zhifang  and
      Chang, Baobao  and
      Wei, Furu",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2022",
    publisher = "Association for Computational Linguistics",
    pages = "8493--8502",
}

@article{YFCC100M,
author = {Thomee, Bart and Shamma, David A. and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
title = {YFCC100M: the new data in multimedia research},
year = {2016},
publisher = {Association for Computing Machinery},
volume = {59},
journal = {Communications of the ACM},
pages = {64–73},
}

@article{
CLIPA,
title={An Inverse Scaling Law for {CLIP} Training},
author={Xianhang Li and Zeyu Wang and Cihang Xie},
 journal = {Advances in Neural Information Processing Systems},
year={2023},
volume={36},
}

@article{vqvae,
 author = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu, koray},
 journal = {Advances in Neural Information Processing Systems},
 title = {Neural Discrete Representation Learning},
  volume = {30},
 year = {2017}
}

@inproceedings{
gshard,
title={GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},
author={Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},
booktitle={International Conference on Learning Representations},
year={2021},
}

@InProceedings{palix,
    author    = {Chen, Xi and Djolonga, Josip and Padlewski, Piotr and Mustafa, Basil and Changpinyo, Soravit and Wu, Jialin and Ruiz, Carlos Riquelme and Goodman, Sebastian and Wang, Xiao and Tay, Yi and Shakeri, Siamak and Dehghani, Mostafa and Salz, Daniel and Lucic, Mario and Tschannen, Michael and Nagrani, Arsha and Hu, Hexiang and Joshi, Mandar and Pang, Bo and Montgomery, Ceslee and Pietrzyk, Paulina and Ritter, Marvin and Piergiovanni, AJ and Minderer, Matthias and Pavetic, Filip and Waters, Austin and Li, Gang and Alabdulmohsin, Ibrahim and Beyer, Lucas and Amelot, Julien and Lee, Kenton and Steiner, Andreas Peter and Li, Yang and Keysers, Daniel and Arnab, Anurag and Xu, Yuanzhong and Rong, Keran and Kolesnikov, Alexander and Seyedhosseini, Mojtaba and Angelova, Anelia and Zhai, Xiaohua and Houlsby, Neil and Soricut, Radu},
    title     = {On Scaling Up a Multilingual Vision and Language Model},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2024},
    pages     = {14432-14444}
}

@article{
LiMoE,
title={Multimodal Contrastive Learning with {LIM}oE: the Language-Image Mixture of Experts},
author={Basil Mustafa and Carlos Riquelme Ruiz and Joan Puigcerver and Rodolphe Jenatton and Neil Houlsby},
journal={Advances in Neural Information Processing Systems},
year={2022},
volume={35},
}

@inproceedings{
pali,
title={Pa{LI}: A Jointly-Scaled Multilingual Language-Image Model},
author={Xi Chen and Xiao Wang and Soravit Changpinyo and AJ Piergiovanni and Piotr Padlewski and Daniel Salz and Sebastian Goodman and Adam Grycner and Basil Mustafa and Lucas Beyer and Alexander Kolesnikov and Joan Puigcerver and Nan Ding and Keran Rong and Hassan Akbari and Gaurav Mishra and Linting Xue and Ashish V Thapliyal and James Bradbury and Weicheng Kuo and Mojtaba Seyedhosseini and Chao Jia and Burcu Karagol Ayan and Carlos Riquelme Ruiz and Andreas Peter Steiner and Anelia Angelova and Xiaohua Zhai and Neil Houlsby and Radu Soricut},
 booktitle = {International Conference on Learning Representations},
year={2023},
}

@InProceedings{TCL,
    author    = {Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
    title     = {Vision-Language Pre-Training With Triple Contrastive Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {15671-15680}
}

@article{
clipshortcut,
title={Demonstrating and Reducing Shortcuts in Vision-Language Representation Learning},
author={Maurits Bleeker and Mariya Hendriksen and Andrew Yates and Maarten de Rijke},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=gfANevPraH},
note={}
}

@inproceedings{
li2022supervision,
title={Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image  Pre-training Paradigm},
author={Yangguang Li and Feng Liang and Lichen Zhao and Yufeng Cui and Wanli Ouyang and Jing Shao and Fengwei Yu and Junjie Yan},
booktitle={International Conference on Learning Representations},
year={2022},
}

@InProceedings{SigLip,
    author    = {Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
    title     = {Sigmoid Loss for Language Image Pre-Training},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    year      = {2023},
    pages     = {11975-11986}
}

@InProceedings{vqa,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {VQA: Visual Question Answering},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
pages = {2425--2433},
year = {2015},
}

@inproceedings{yao2017boosting,
  title={Boosting image captioning with attributes},
  author={Yao, Ting and Pan, Yingwei and Li, Yehao and Qiu, Zhaofan and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4904--4912},
  year={2017}
}

@misc{EVA,
      title={EVA-CLIP: Improved Training Techniques for CLIP at Scale}, 
      author={Quan Sun and Yuxin Fang and Ledell Wu and Xinlong Wang and Yue Cao},
      year={2023},
      eprint={2303.15389},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.15389}, 
}

@article{
CoCa,
title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
}

@InProceedings{MaskCLIP,
    author    = {Dong, Xiaoyi and Bao, Jianmin and Zheng, Yinglin and Zhang, Ting and Chen, Dongdong and Yang, Hao and Zeng, Ming and Zhang, Weiming and Yuan, Lu and Chen, Dong and Wen, Fang and Yu, Nenghai},
    title     = {MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2023},
    pages     = {10995-11005}
}

@inproceedings{yang2019auto,
  title={Auto-encoding scene graphs for image captioning},
  author={Yang, Xu and Tang, Kaihua and Zhang, Hanwang and Cai, Jianfei},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {10677-10686},
  year={2019}
}

@inproceedings{
bow,
title={When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?},
author={Mert Yuksekgonul and Federico Bianchi and Pratyusha Kalluri and Dan Jurafsky and James Zou},
booktitle={International Conference on Learning Representations},
year={2023},
}

@preprint{SEER,
      title={Self-supervised Pretraining of Visual Features in the Wild}, 
      author={Priya Goyal and Mathilde Caron and Benjamin Lefaudeux and Min Xu and Pengchao Wang and Vivek Pai and Mannat Singh and Vitaliy Liptchinsky and Ishan Misra and Armand Joulin and Piotr Bojanowski},
      year={2021},
      eprint={2103.01988},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/2103.01988}, 
}

@InProceedings{ACLIP,
    author    = {Yang, Yifan and Huang, Weiquan and Wei, Yixuan and Peng, Houwen and Jiang, Xinyang and Jiang, Huiqiang and Wei, Fangyun and Wang, Yin and Hu, Han and Qiu, Lili and Yang, Yuqing},
    title     = {Attentive Mask CLIP},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
    month     = {October},
    year      = {2023},
    pages     = {2771-2781}
}

@article{schuhmann2022laion5bopenlargescaledataset,
 author = {Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and Schramowski, Patrick and Kundurthy, Srivatsa and Crowson, Katherine and Schmidt, Ludwig and Kaczmarczyk, Robert and Jitsev, Jenia},
 journal = {Advances in Neural Information Processing Systems},
 title = {LAION-5B: An open large-scale dataset for training next generation image-text models},
 volume = {35},
 year = {2022}
}

@article{MM-C4,
 author = {Zhu, Wanrong and Hessel, Jack and Awadalla, Anas and Gadre, Samir Yitzhak and Dodge, Jesse and Fang, Alex and Yu, Youngjae and Schmidt, Ludwig and Wang, William Yang and Choi, Yejin},
 journal = {Advances in Neural Information Processing Systems},
 title = {Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with Text},
 volume = {36},
 year = {2023}
}


@InProceedings{Zhong_2022_CVPR,
    author    = {Zhong, Yiwu and Yang, Jianwei and Zhang, Pengchuan and Li, Chunyuan and Codella, Noel and Li, Liunian Harold and Zhou, Luowei and Dai, Xiyang and Yuan, Lu and Li, Yin and Gao, Jianfeng},
    title     = {RegionCLIP: Region-Based Language-Image Pretraining},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {16793-16803}
}

@article{detclip,
 author = {Yao, Lewei and Han, Jianhua and Wen, Youpeng and Liang, Xiaodan and Xu, Dan and Zhang, Wei and Li, Zhenguo and XU, Chunjing and Xu, Hang},
 journal = {Advances in Neural Information Processing Systems},
 title = {DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for Open-world Detection},
 volume = {35},
 year = {2022}
}

@InProceedings{denseclip,
    author    = {Rao, Yongming and Zhao, Wenliang and Chen, Guangyi and Tang, Yansong and Zhu, Zheng and Huang, Guan and Zhou, Jie and Lu, Jiwen},
    title     = {DenseCLIP: Language-Guided Dense Prediction With Context-Aware Prompting},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {18082-18091}
}

@InProceedings{detclip-2,
    author    = {Yao, Lewei and Han, Jianhua and Liang, Xiaodan and Xu, Dan and Zhang, Wei and Li, Zhenguo and Xu, Hang},
    title     = {DetCLIPv2: Scalable Open-Vocabulary Object Detection Pre-Training via Word-Region Alignment},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2023},
    pages     = {23497-23506}
}

@InProceedings{detclip-3,
    author    = {Yao, Lewei and Pi, Renjie and Han, Jianhua and Liang, Xiaodan and Xu, Hang and Zhang, Wei and Li, Zhenguo and Xu, Dan},
    title     = {DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2024},
    pages     = {27391-27401}
}

@InProceedings{glip,
    author    = {Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and Chang, Kai-Wei and Gao, Jianfeng},
    title     = {Grounded Language-Image Pre-Training},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {10965-10975}
}

@inproceedings{
F-VLM,
title={Open-Vocabulary Object Detection upon Frozen Vision and Language Models},
author={Weicheng Kuo and Yin Cui and Xiuye Gu and AJ Piergiovanni and Anelia Angelova},
booktitle={International Conference on Learning Representations},
year={2023},
}

@inproceedings{
ViLD,
title={Open-vocabulary Object Detection via Vision and Language Knowledge Distillation},
author={Xiuye Gu and Tsung-Yi Lin and Weicheng Kuo and Yin Cui},
booktitle={International Conference on Learning Representations},
year={2022},
}

@article{OBELICS,
 author = {Lauren\c{c}on, Hugo and Saulnier, Lucile and Tronchon, Leo and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander and Kiela, Douwe and Cord, Matthieu and Sanh, Victor},
 journal = {Advances in Neural Information Processing Systems},
 title = {OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
 volume = {36},
 year = {2023}
}

@misc{COYO-700m,
  title         = {COYO-700M: Image-Text Pair Dataset},
  author        = {Byeon, Minwoo and Park, Beomhee and Kim, Haecheon and Lee, Sungjun and Baek, Woonhyuk and Kim, Saehoon},
  year          = {2022},
  howpublished  = {\url{https://github.com/kakaobrain/coyo-dataset}},
}

@inproceedings{
xu2024demystifying,
title={Demystifying {CLIP} Data},
author={Hu Xu and Saining Xie and Xiaoqing Tan and Po-Yao Huang and Russell Howes and Vasu Sharma and Shang-Wen Li and Gargi Ghosh and Luke Zettlemoyer and Christoph Feichtenhofer},
booktitle={International Conference on Learning Representations},
year={2024},
}

@inproceedings{SLIP,
author = {Mu, Norman and Kirillov, Alexander and Wagner, David and Xie, Saining},
title = {SLIP: Self-supervision Meets Language-Image Pre-training},
year = {2022},
booktitle = {Proceedings of the European Conference on Computer Vision},
organization = {Springer},
pages = {529–544},
}

@inproceedings{languagehelpvision,
    title = "Does language help generalization in vision models?",
    author = "Devillers, Benjamin  and
      Choksi, Bhavin  and
      Bielawski, Romain  and
      VanRullen, Rufin",
    editor = "Bisazza, Arianna  and
      Abend, Omri",
    booktitle = "Proceedings of the 25th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.conll-1.13/",
    doi = "10.18653/v1/2021.conll-1.13",
    pages = "171--182",
    abstract = "Vision models trained on multimodal datasets can benefit from the wide availability of large image-caption datasets. A recent model (CLIP) was found to generalize well in zero-shot and transfer learning settings. This could imply that linguistic or {\textquotedblleft}semantic grounding{\textquotedblright} confers additional generalization abilities to the visual feature space. Here, we systematically evaluate various multimodal architectures and vision-only models in terms of unsupervised clustering, few-shot learning, transfer learning and adversarial robustness. In each setting, multimodal training produced no additional generalization capability compared to standard supervised visual training. We conclude that work is still required for semantic grounding to help improve vision models."
}

@inproceedings{
clip-generalize,
title={A Sober Look at the Robustness of {CLIP}s to Spurious Features},
author={Qizhou Wang and Yong Lin and Yongqiang Chen and Ludwig Schmidt and Bo Han and Tong Zhang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=wWyumwEYV8}
}

@preprint{CLIPA-v2,
      title={CLIPA-v2: Scaling CLIP Training with 81.1\% Zero-shot ImageNet Accuracy within a \$10,000 Budget; An Extra \$4,000 Unlocks 81.8\% Accuracy}, 
      author={Xianhang Li and Zeyu Wang and Cihang Xie},
      year={2023},
      eprint={2306.15658},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/2306.15658}, 
}

@misc{VisionZIP,
      title={VisionZip: Longer is Better but Not Necessary in Vision Language Models}, 
      author={Senqiao Yang and Yukang Chen and Zhuotao Tian and Chengyao Wang and Jingyao Li and Bei Yu and Jiaya Jia},
      year={2024},
      eprint={2412.04467},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.04467}, 
}

@InProceedings{MobileCLIP,
    author    = {Vasu, Pavan Kumar Anasosalu and Pouransari, Hadi and Faghri, Fartash and Vemulapalli, Raviteja and Tuzel, Oncel},
    title     = {MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2024},
    pages     = {15963-15974}
}

@inproceedings{guo2020efficientderain,
      title={EfficientDeRain: Learning Pixel-wise Dilation Filtering for High-Efficiency Single-Image Deraining}, 
      author={Qing Guo and Jingyang Sun and Felix Juefei-Xu and Lei Ma and Xiaofei Xie and Wei Feng and Yang Liu},
      year={2021},
      booktitle={AAAI}
}


@inproceedings{word2vec,
  author       = {Tom{\'{a}}s Mikolov and
                  Kai Chen and
                  Greg Corrado and
                  Jeffrey Dean},
  title        = {Efficient Estimation of Word Representations in Vector Space},
booktitle = {International Conference on Learning Representations},
  year         = {2013},
}


@article{distword2vec,
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
title = {Distributed representations of words and phrases and their compositionality},
year = {2013},
journal = {Advances in Neural Information Processing Systems},
volume = {26},
}


@inproceedings{BERTmask,
    title = "Should You Mask 15{\%} in Masked Language Modeling?",
    author = "Wettig, Alexander  and
      Gao, Tianyu  and
      Zhong, Zexuan  and
      Chen, Danqi",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.217/",
    doi = "10.18653/v1/2023.eacl-main.217",
    pages = "2985--3000",
    abstract = "Masked language models (MLMs) conventionally mask 15{\%} of tokens due to the belief that more masking would leave insufficient context to learn good representations; this masking rate has been widely used, regardless of model sizes or masking strategies. In this work, we revisit this important choice of MLM pre-training. We first establish that 15{\%} is not universally optimal, and larger models should adopt a higher masking rate. Specifically, we find that masking 40{\%} outperforms 15{\%} for BERT-large size models on GLUE and SQuAD. Interestingly, an extremely high masking rate of 80{\%} can still preserve 95{\%} fine-tuning performance and most of the accuracy in linguistic probing, challenging the conventional wisdom about the role of the masking rate. We then examine the interplay between masking rates and masking strategies and find that uniform masking requires a higher masking rate compared to sophisticated masking strategies such as span or PMI masking. Finally, we argue that increasing the masking rate has two distinct effects: it leads to more corruption, which makes the prediction task more difficult; it also enables more predictions, which benefits optimization. Using this framework, we revisit BERT`s 80-10-10 corruption strategy. Together, our results contribute to a better understanding of MLM pre-training."
}

@InProceedings{vilt,
  title = 	 {ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision},
  author =       {Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5583--5594},
  year = 	 {2021},
  organization =    {PMLR},
}

@InProceedings{SOHO,
    author    = {Huang, Zhicheng and Zeng, Zhaoyang and Huang, Yupan and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
    title     = {Seeing Out of the Box: End-to-End Pre-Training for Vision-Language Representation Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2021},
    pages     = {12976-12985}
}

@preprint{pixelbert,
      title={Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers}, 
      author={Zhicheng Huang and Zhaoyang Zeng and Bei Liu and Dongmei Fu and Jianlong Fu},
      year={2020},
      eprint={2004.00849},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/2004.00849}, 
}

@article{
catastrophic,
author = {James Kirkpatrick  and Razvan Pascanu  and Neil Rabinowitz  and Joel Veness  and Guillaume Desjardins  and Andrei A. Rusu  and Kieran Milan  and John Quan  and Tiago Ramalho  and Agnieszka Grabska-Barwinska  and Demis Hassabis  and Claudia Clopath  and Dharshan Kumaran  and Raia Hadsell },
title = {Overcoming catastrophic forgetting in neural networks},
journal = {Proceedings of the National Academy of Sciences},
volume = {114},
number = {13},
pages = {3521-3526},
year = {2017},
}


@InProceedings{butd,
author = {Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
title = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
month = {June},
pages = {6077-6086},
year = {2018}
}

@inproceedings{
vl-bert,
title={VL-BERT: Pre-training of Generic Visual-Linguistic Representations},
author={Weijie Su and Xizhou Zhu and Yue Cao and Bin Li and Lewei Lu and Furu Wei and Jifeng Dai},
booktitle={International Conference on Learning Representations},
year={2020},
}

@preprint{visualbert,
      title={VisualBERT: A Simple and Performant Baseline for Vision and Language}, 
      author={Liunian Harold Li and Mark Yatskar and Da Yin and Cho-Jui Hsieh and Kai-Wei Chang},
      year={2019},
      eprint={1908.03557},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/1908.03557}, 
}

@InProceedings{clipseg,
    author    = {L\"uddecke, Timo and Ecker, Alexander},
    title     = {Image Segmentation Using Text and Image Prompts},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {7086-7096}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International Journal of Computer Vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3558--3568},
  year={2021}
}

@inproceedings{BERT,
    title = "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    pages = "4171--4186",
}

@article{gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  year={2019}
}

@inproceedings{LocNar,
  title={Connecting vision and language with localized narratives},
  author={Pont-Tuset, Jordi and Uijlings, Jasper and Changpinyo, Soravit and Soricut, Radu and Ferrari, Vittorio},
  booktitle = {Proceedings of the European Conference on Computer Vision},
  pages={647--664},
  year={2020},
  organization={Springer}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={Proceedings of the 38th International Conference on Machine Learning},
  organization={PMLR},
  pages={8748--8763},
  year={2021},
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={Proceedings of the 38th International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR},
}

@article{pham2023combined,
  title={Combined scaling for zero-shot transfer learning},
  author={Pham, Hieu and Dai, Zihang and Ghiasi, Golnaz and Kawaguchi, Kenji and Liu, Hanxiao and Yu, Adams Wei and Yu, Jiahui and Chen, Yi-Ting and Luong, Minh-Thang and Wu, Yonghui and others},
  journal={Neurocomputing},
  volume={555},
  pages={126658},
  year={2023},
  issn = {0925-2312},
  publisher={Elsevier}
}

@article{miller1995wordnet,
  title={WordNet: a lexical database for English},
  author={Miller, George A},
  journal={Communications of the ACM},
  volume={38},
  pages={39--41},
  year={1995},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deng2009imagenet,
  title={ImageNet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2009},
    pages     = {248-255},
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{chen2019htc,
  title={Hybrid task cascade for instance segmentation},
  author={Chen, Kai and Pang, Jiangmiao and Wang, Jiaqi and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Shi, Jianping and Ouyang, Wanli and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4974--4983},
  year={2019}
}

@inproceedings{xiao2018upernet,
 author = {Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
 booktitle = {Proceedings of the European Conference on Computer Vision},
organization = {Springer},
 pages = {418--434},
 title = {Unified Perceptual Parsing for Scene Understanding},
 year = {2018}
}

@inproceedings{Mask-rcnn,
  title={Mask R-CNN},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2961--2969},
  year={2017}
}

@preprint{glpdepth,
  title={Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth},
  author={Kim, Doyeon and Ka, Woonghyun and Ahn, Pyungwhan and Joo, Donggyu and Chun, Sehwan and Kim, Junmo},
  eprint={2201.07436},
  archiveprefix={arXiv},
  url={https://arxiv.org/abs/2201.07436},
  year={2022}
}

@InProceedings{Sun_2017_JFT300m,
author = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
title = {Revisiting Unreasonable Effectiveness of Data in Deep Learning Era},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
month = {Oct},
pages = {843-852},
year = {2017}
}

@InProceedings{vit22b,
  title = 	 {Scaling Vision Transformers to 22 Billion Parameters},
  author =       {Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and Jenatton, Rodolphe and Beyer, Lucas and Tschannen, Michael and Arnab, Anurag and Wang, Xiao and Riquelme Ruiz, Carlos and Minderer, Matthias and Puigcerver, Joan and Evci, Utku and Kumar, Manoj and Steenkiste, Sjoerd Van and Elsayed, Gamaleldin Fathy and Mahendran, Aravindh and Yu, Fisher and Oliver, Avital and Huot, Fantine and Bastings, Jasmijn and Collier, Mark and Gritsenko, Alexey A. and Birodkar, Vighnesh and Vasconcelos, Cristina Nader and Tay, Yi and Mensink, Thomas and Kolesnikov, Alexander and Pavetic, Filip and Tran, Dustin and Kipf, Thomas and Lucic, Mario and Zhai, Xiaohua and Keysers, Daniel and Harmsen, Jeremiah J. and Houlsby, Neil},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {7480--7512},
  year = 	 {2023},
  organization =    {PMLR},
}


@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12104--12113},
  year={2022}
}

@inproceedings{ramesh2021dalle1,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={Proceedings of the 38th International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@inproceedings{swinv2cvpr,
  title={Swin Transformer V2: Scaling Up Capacity and Resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12009--12019},
  year={2022}
}

@inproceedings{
zhang2022dino,
title={{DINO}: {DETR} with Improved DeNoising Anchor Boxes for End-to-End Object Detection},
author={Hao Zhang and Feng Li and Shilong Liu and Lei Zhang and Hang Su and Jun Zhu and Lionel Ni and Heung-Yeung Shum},
booktitle={International Conference on Learning Representations},
year={2023},
}

@inproceedings{
chen2022vitadapter,
title={Vision Transformer Adapter for Dense Predictions},
author={Zhe Chen and Yuchen Duan and Wenhai Wang and Junjun He and Tong Lu and Jifeng Dai and Yu Qiao},
booktitle={International Conference on Learning Representations},
year={2023},
}

@InProceedings{li2022mask,
    author    = {Li, Feng and Zhang, Hao and Xu, Huaizhe and Liu, Shilong and Zhang, Lei and Ni, Lionel M. and Shum, Heung-Yeung},
    title     = {Mask DINO: Towards a Unified Transformer-Based Framework for Object Detection and Segmentation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2023},
    pages     = {3041-3050}
}

@article{
GLIPv2_2022,
title={{GLIP}v2: Unifying Localization and Vision-Language Understanding },
author={Haotian Zhang and Pengchuan Zhang and Xiaowei Hu and Yen-Chun Chen and Liunian Harold Li and Xiyang Dai and Lijuan Wang and Lu Yuan and Jenq-Neng Hwang and Jianfeng Gao},
journal={Advances in Neural Information Processing Systems},
volume={35},
year={2022},
}

@preprint{yuan2021florence,
      title={Florence: A New Foundation Model for Computer Vision}, 
      author={Lu Yuan and Dongdong Chen and Yi-Ling Chen and Noel Codella and Xiyang Dai and Jianfeng Gao and Houdong Hu and Xuedong Huang and Boxin Li and Chunyuan Li and Ce Liu and Mengchen Liu and Zicheng Liu and Yumao Lu and Yu Shi and Lijuan Wang and Jianfeng Wang and Bin Xiao and Zhen Xiao and Jianwei Yang and Michael Zeng and Luowei Zhou and Pengchuan Zhang},
      year={2021},
      eprint={2111.11432},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2111.11432}, 
}

@article{imagen,
 author = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and Ho, Jonathan and Fleet, David J and Norouzi, Mohammad},
 journal = {Advances in Neural Information Processing Systems},
 title = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
 volume = {35},
 year = {2022}
}

@InProceedings{cider,
author = {Vedantam, Ramakrishna and Lawrence Zitnick, C. and Parikh, Devi},
title = {CIDEr: Consensus-Based Image Description Evaluation},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
month = {June},
pages = {4566-4575},
year = {2015}
}

@inproceedings{uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle = {Proceedings of the European Conference on Computer Vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@article{sbu,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  year={2011}
}

@article{Imagebart,
  title={Imagebart: Bidirectional context with multinomial diffusion for autoregressive image synthesis},
  author={Esser, Patrick and Rombach, Robin and Blattmann, Andreas and Ommer, Bjorn},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{meter,
  title={An empirical study of training end-to-end vision-and-language transformers},
  author={Dou, Zi-Yi and Xu, Yichong and Gan, Zhe and Wang, Jianfeng and Wang, Shuohang and Wang, Lijuan and Zhu, Chenguang and Zhang, Pengchuan and Yuan, Lu and Peng, Nanyun and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18166--18176},
  year={2022}
}

@article{structddm,
 author = {Austin, Jacob and Johnson, Daniel D. and Ho, Jonathan and Tarlow, Daniel and van den Berg, Rianne},
 journal = {Advances in Neural Information Processing Systems},
 title = {Structured Denoising Diffusion Models in Discrete State-Spaces},
 volume = {34},
 year = {2021}
}


@inproceedings{OSCAR,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle = {Proceedings of the European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{CLIPScore,
    title = "{CLIPS}core: A Reference-free Evaluation Metric for Image Captioning",
    author = "Hessel, Jack  and
      Holtzman, Ari  and
      Forbes, Maxwell  and
      Le Bras, Ronan  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    publisher = "Association for Computational Linguistics",
    pages = "7514--7528",
}

@InProceedings{VQ-diffusion,
    author    = {Gu, Shuyang and Chen, Dong and Bao, Jianmin and Wen, Fang and Zhang, Bo and Chen, Dongdong and Yuan, Lu and Guo, Baining},
    title     = {Vector Quantized Diffusion Model for Text-to-Image Synthesis},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {10696-10706}
}

@article{
GIT,
title={{GIT}: A Generative Image-to-text Transformer for Vision and Language},
author={Jianfeng Wang and Zhengyuan Yang and Xiaowei Hu and Linjie Li and Kevin Lin and Zhe Gan and Zicheng Liu and Ce Liu and Lijuan Wang},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
}

@inproceedings{
SimVLM,
title={Sim{VLM}: Simple Visual Language Model Pretraining with Weak Supervision},
author={Zirui Wang and Jiahui Yu and Adams Wei Yu and Zihang Dai and Yulia Tsvetkov and Yuan Cao},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{ViTCap,
  title={Injecting semantic concepts into end-to-end image captioning},
  author={Fang, Zhiyuan and Wang, Jianfeng and Hu, Xiaowei and Liang, Lin and Gan, Zhe and Wang, Lijuan and Yang, Yezhou and Liu, Zicheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18009--18019},
  year={2022}
}

@preprint{UFO,
      title={UFO: A UniFied TransfOrmer for Vision-Language Representation Learning}, 
      author={Jianfeng Wang and Xiaowei Hu and Zhe Gan and Zhengyuan Yang and Xiyang Dai and Zicheng Liu and Yumao Lu and Lijuan Wang},
      year={2021},
      eprint={2111.10023},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2111.10023}, 
}


@inproceedings{VinVL,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5579--5588},
  year={2021}
}

@InProceedings{blip-2,
  title = 	 {{BLIP}-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author =       {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {19730--19742},
  year = 	 {2023},
  organization =    {PMLR},
}

@misc{VSIBench,
      title={Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces}, 
      author={Jihan Yang and Shusheng Yang and Anjali W. Gupta and Rilyn Han and Li Fei-Fei and Saining Xie},
      year={2024},
      eprint={2412.14171},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.14171}, 
}

@inproceedings{weblm,
author = {Xu, Hongshen and Chen, Lu and Zhao, Zihan and Ma, Da and Cao, Ruisheng and Zhu, Zichen and Yu, Kai},
title = {Hierarchical Multimodal Pre-training for Visually Rich Webpage Understanding},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635753},
doi = {10.1145/3616855.3635753},
abstract = {The growing prevalence of visually rich documents, such as webpages and scanned/digital-born documents (images, PDFs, etc.), has led to increased interest in automatic document understanding and information extraction across academia and industry. Although various document modalities, including image, text, layout, and structure, facilitate human information retrieval, the interconnected nature of these modalities presents challenges for neural networks. In this paper, we introduce WebLM, a multimodal pre-training network designed to address the limitations of solely modeling text and structure modalities of HTML in webpages. Instead of processing document images as unified natural images, WebLM integrates the hierarchical structure of document images to enhance the understanding of markup-language-based documents. Additionally, we propose several pre-training tasks to model the interaction among text, structure, and image modalities effectively. Empirical results demonstrate that the pre-trained WebLM significantly surpasses previous state-of-the-art pre-trained models across several webpage understanding tasks. The pre-trained models and code are available at https://github.com/X-LANCE/weblm.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {864–872},
numpages = {9},
keywords = {multimodal pre-training, visually rich document understanding, web reading comprehension},
location = {Merida, Mexico},
series = {WSDM '24}
}

@InProceedings{S4,
    author    = {Gao, Yuan and Shi, Kunyu and Zhu, Pengkai and Belval, Edouard and Nuriel, Oren and Appalaraju, Srikar and Ghadar, Shabnam and Tu, Zhuowen and Mahadevan, Vijay and Soatto, Stefano},
    title     = {Enhancing Vision-Language Pre-training with Rich Supervisions},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2024},
    pages     = {13480-13491}
}

@inproceedings{vln,
    title = "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions",
    author = "Gu, Jing  and
      Stefani, Eliana  and
      Wu, Qi  and
      Thomason, Jesse  and
      Wang, Xin",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2022",
    publisher = "Association for Computational Linguistics",
    pages = "7606--7623",
}

@book{mindchildren,
author = {Moravec, Hans},
title = {Mind children: the future of robot and human intelligence},
year = {1988},
publisher = {Harvard University Press},
}

@preprint{gemini,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M. Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R. Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W. Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco and Adrià Puigdomènech Badia and David Reitter and Mianna Chen and Jenny Brennan and Clara Rivera and Sergey Brin and Shariq Iqbal and Gabriela Surita and Jane Labanowski and Abhi Rao and Stephanie Winkler and Emilio Parisotto and Yiming Gu and Kate Olszewska and Ravi Addanki and Antoine Miech and Annie Louis and Denis Teplyashin and Geoff Brown and Elliot Catt and Jan Balaguer and Jackie Xiang and Pidong Wang and Zoe Ashwood and Anton Briukhov and Albert Webson and Sanjay Ganapathy and Smit Sanghavi and Ajay Kannan and Ming-Wei Chang and Axel Stjerngren and Josip Djolonga and Yuting Sun and Ankur Bapna and Matthew Aitchison and Pedram Pejman and Henryk Michalewski and Tianhe Yu and Cindy Wang and Juliette Love and Junwhan Ahn and Dawn Bloxwich and Kehang Han and Peter Humphreys and Thibault Sellam and James Bradbury and Varun Godbole and Sina Samangooei and Bogdan Damoc and Alex Kaskasoli and Sébastien M. R. Arnold and Vijay Vasudevan and Shubham Agrawal and Jason Riesa and Dmitry Lepikhin and Richard Tanburn and Srivatsan Srinivasan and Hyeontaek Lim and Sarah Hodkinson and Pranav Shyam and Johan Ferret and Steven Hand and Ankush Garg and Tom Le Paine and Jian Li and Yujia Li and Minh Giang and Alexander Neitz and Zaheer Abbas and Sarah York and Machel Reid and Elizabeth Cole and Aakanksha Chowdhery and Dipanjan Das and Dominika Rogozińska and Vitaliy Nikolaev and Pablo Sprechmann and Zachary Nado and Lukas Zilka and Flavien Prost and Luheng He and Marianne Monteiro and Gaurav Mishra and Chris Welty and Josh Newlan and Dawei Jia and Miltiadis Allamanis and Clara Huiyi Hu and Raoul de Liedekerke and Justin Gilmer and Carl Saroufim and Shruti Rijhwani and Shaobo Hou and Disha Shrivastava and Anirudh Baddepudi and Alex Goldin and Adnan Ozturel and Albin Cassirer and Yunhan Xu and Daniel Sohn and Devendra Sachan and Reinald Kim Amplayo and Craig Swanson and Dessie Petrova and Shashi Narayan and Arthur Guez and Siddhartha Brahma and Jessica Landon and Miteyan Patel and Ruizhe Zhao and Kevin Villela and Luyu Wang and Wenhao Jia and Matthew Rahtz and Mai Giménez and Legg Yeung and James Keeling and Petko Georgiev and Diana Mincu and Boxi Wu and Salem Haykal and Rachel Saputro and Kiran Vodrahalli and James Qin and Zeynep Cankara and Abhanshu Sharma and Nick Fernando and Will Hawkins and Behnam Neyshabur and Solomon Kim and Adrian Hutter and Priyanka Agrawal and Alex Castro-Ros and George van den Driessche and Tao Wang and Fan Yang and Shuo-yiin Chang and Paul Komarek and Ross McIlroy and Mario Lučić and Guodong Zhang and Wael Farhan and Michael Sharman and Paul Natsev and Paul Michel and Yamini Bansal and Siyuan Qiao and Kris Cao and Siamak Shakeri and Christina Butterfield and Justin Chung and Paul Kishan Rubenstein and Shivani Agrawal and Arthur Mensch and Kedar Soparkar and Karel Lenc and Timothy Chung and Aedan Pope and Loren Maggiore and Jackie Kay and Priya Jhakra and Shibo Wang and Joshua Maynez and Mary Phuong and Taylor Tobin and Andrea Tacchetti and Maja Trebacz and Kevin Robinson and Yash Katariya and Sebastian Riedel and Paige Bailey and Kefan Xiao and Nimesh Ghelani and Lora Aroyo and Ambrose Slone and Neil Houlsby and Xuehan Xiong and Zhen Yang and Elena Gribovskaya and Jonas Adler and Mateo Wirth and Lisa Lee and Music Li and Thais Kagohara and Jay Pavagadhi and Sophie Bridgers and Anna Bortsova and Sanjay Ghemawat and Zafarali Ahmed and Tianqi Liu and Richard Powell and Vijay Bolina and Mariko Iinuma and Polina Zablotskaia and James Besley and Da-Woon Chung and Timothy Dozat and Ramona Comanescu and Xiance Si and Jeremy Greer and Guolong Su and Martin Polacek and Raphaël Lopez Kaufman and Simon Tokumine and Hexiang Hu and Elena Buchatskaya and Yingjie Miao and Mohamed Elhawaty and Aditya Siddhant and Nenad Tomasev and Jinwei Xing and Christina Greer and Helen Miller and Shereen Ashraf and Aurko Roy and Zizhao Zhang and Ada Ma and Angelos Filos and Milos Besta and Rory Blevins and Ted Klimenko and Chih-Kuan Yeh and Soravit Changpinyo and Jiaqi Mu and Oscar Chang and Mantas Pajarskas and Carrie Muir and Vered Cohen and Charline Le Lan and Krishna Haridasan and Amit Marathe and Steven Hansen and Sholto Douglas and Rajkumar Samuel and Mingqiu Wang and Sophia Austin and Chang Lan and Jiepu Jiang and Justin Chiu and Jaime Alonso Lorenzo and Lars Lowe Sjösund and Sébastien Cevey and Zach Gleicher and Thi Avrahami and Anudhyan Boral and Hansa Srinivasan and Vittorio Selo and Rhys May and Konstantinos Aisopos and Léonard Hussenot and Livio Baldini Soares and Kate Baumli and Michael B. Chang and Adrià Recasens and Ben Caine and Alexander Pritzel and Filip Pavetic and Fabio Pardo and Anita Gergely and Justin Frye and Vinay Ramasesh and Dan Horgan and Kartikeya Badola and Nora Kassner and Subhrajit Roy and Ethan Dyer and Víctor Campos Campos and Alex Tomala and Yunhao Tang and Dalia El Badawy and Elspeth White and Basil Mustafa and Oran Lang and Abhishek Jindal and Sharad Vikram and Zhitao Gong and Sergi Caelles and Ross Hemsley and Gregory Thornton and Fangxiaoyu Feng and Wojciech Stokowiec and Ce Zheng and Phoebe Thacker and Çağlar Ünlü and Zhishuai Zhang and Mohammad Saleh and James Svensson and Max Bileschi and Piyush Patil and Ankesh Anand and Roman Ring and Katerina Tsihlas and Arpi Vezer and Marco Selvi and Toby Shevlane and Mikel Rodriguez and Tom Kwiatkowski and Samira Daruki and Keran Rong and Allan Dafoe and Nicholas FitzGerald and Keren Gu-Lemberg and Mina Khan and Lisa Anne Hendricks and Marie Pellat and Vladimir Feinberg and James Cobon-Kerr and Tara Sainath and Maribeth Rauh and Sayed Hadi Hashemi and Richard Ives and Yana Hasson and Eric Noland and Yuan Cao and Nathan Byrd and Le Hou and Qingze Wang and Thibault Sottiaux and Michela Paganini and Jean-Baptiste Lespiau and Alexandre Moufarek and Samer Hassan and Kaushik Shivakumar and Joost van Amersfoort and Amol Mandhane and Pratik Joshi and Anirudh Goyal and Matthew Tung and Andrew Brock and Hannah Sheahan and Vedant Misra and Cheng Li and Nemanja Rakićević and Mostafa Dehghani and Fangyu Liu and Sid Mittal and Junhyuk Oh and Seb Noury and Eren Sezener and Fantine Huot and Matthew Lamm and Nicola De Cao and Charlie Chen and Sidharth Mudgal and Romina Stella and Kevin Brooks and Gautam Vasudevan and Chenxi Liu and Mainak Chain and Nivedita Melinkeri and Aaron Cohen and Venus Wang and Kristie Seymore and Sergey Zubkov and Rahul Goel and Summer Yue and Sai Krishnakumaran and Brian Albert and Nate Hurley and Motoki Sano and Anhad Mohananey and Jonah Joughin and Egor Filonov and Tomasz Kępa and Yomna Eldawy and Jiawern Lim and Rahul Rishi and Shirin Badiezadegan and Taylor Bos and Jerry Chang and Sanil Jain and Sri Gayatri Sundara Padmanabhan and Subha Puttagunta and Kalpesh Krishna and Leslie Baker and Norbert Kalb and Vamsi Bedapudi and Adam Kurzrok and Shuntong Lei and Anthony Yu and Oren Litvin and Xiang Zhou and Zhichun Wu and Sam Sobell and Andrea Siciliano and Alan Papir and Robby Neale and Jonas Bragagnolo and Tej Toor and Tina Chen and Valentin Anklin and Feiran Wang and Richie Feng and Milad Gholami and Kevin Ling and Lijuan Liu and Jules Walter and Hamid Moghaddam and Arun Kishore and Jakub Adamek and Tyler Mercado and Jonathan Mallinson and Siddhinita Wandekar and Stephen Cagle and Eran Ofek and Guillermo Garrido and Clemens Lombriser and Maksim Mukha and Botu Sun and Hafeezul Rahman Mohammad and Josip Matak and Yadi Qian and Vikas Peswani and Pawel Janus and Quan Yuan and Leif Schelin and Oana David and Ankur Garg and Yifan He and Oleksii Duzhyi and Anton Älgmyr and Timothée Lottaz and Qi Li and Vikas Yadav and Luyao Xu and Alex Chinien and Rakesh Shivanna and Aleksandr Chuklin and Josie Li and Carrie Spadine and Travis Wolfe and Kareem Mohamed and Subhabrata Das and Zihang Dai and Kyle He and Daniel von Dincklage and Shyam Upadhyay and Akanksha Maurya and Luyan Chi and Sebastian Krause and Khalid Salama and Pam G Rabinovitch and Pavan Kumar Reddy M and Aarush Selvan and Mikhail Dektiarev and Golnaz Ghiasi and Erdem Guven and Himanshu Gupta and Boyi Liu and Deepak Sharma and Idan Heimlich Shtacher and Shachi Paul and Oscar Akerlund and François-Xavier Aubet and Terry Huang and Chen Zhu and Eric Zhu and Elico Teixeira and Matthew Fritze and Francesco Bertolini and Liana-Eleonora Marinescu and Martin Bölle and Dominik Paulus and Khyatti Gupta and Tejasi Latkar and Max Chang and Jason Sanders and Roopa Wilson and Xuewei Wu and Yi-Xuan Tan and Lam Nguyen Thiet and Tulsee Doshi and Sid Lall and Swaroop Mishra and Wanming Chen and Thang Luong and Seth Benjamin and Jasmine Lee and Ewa Andrejczuk and Dominik Rabiej and Vipul Ranjan and Krzysztof Styrc and Pengcheng Yin and Jon Simon and Malcolm Rose Harriott and Mudit Bansal and Alexei Robsky and Geoff Bacon and David Greene and Daniil Mirylenka and Chen Zhou and Obaid Sarvana and Abhimanyu Goyal and Samuel Andermatt and Patrick Siegler and Ben Horn and Assaf Israel and Francesco Pongetti and Chih-Wei "Louis" Chen and Marco Selvatici and Pedro Silva and Kathie Wang and Jackson Tolins and Kelvin Guu and Roey Yogev and Xiaochen Cai and Alessandro Agostini and Maulik Shah and Hung Nguyen and Noah Ó Donnaile and Sébastien Pereira and Linda Friso and Adam Stambler and Adam Kurzrok and Chenkai Kuang and Yan Romanikhin and Mark Geller and ZJ Yan and Kane Jang and Cheng-Chun Lee and Wojciech Fica and Eric Malmi and Qijun Tan and Dan Banica and Daniel Balle and Ryan Pham and Yanping Huang and Diana Avram and Hongzhi Shi and Jasjot Singh and Chris Hidey and Niharika Ahuja and Pranab Saxena and Dan Dooley and Srividya Pranavi Potharaju and Eileen O'Neill and Anand Gokulchandran and Ryan Foley and Kai Zhao and Mike Dusenberry and Yuan Liu and Pulkit Mehta and Ragha Kotikalapudi and Chalence Safranek-Shrader and Andrew Goodman and Joshua Kessinger and Eran Globen and Prateek Kolhar and Chris Gorgolewski and Ali Ibrahim and Yang Song and Ali Eichenbaum and Thomas Brovelli and Sahitya Potluri and Preethi Lahoti and Cip Baetu and Ali Ghorbani and Charles Chen and Andy Crawford and Shalini Pal and Mukund Sridhar and Petru Gurita and Asier Mujika and Igor Petrovski and Pierre-Louis Cedoz and Chenmei Li and Shiyuan Chen and Niccolò Dal Santo and Siddharth Goyal and Jitesh Punjabi and Karthik Kappaganthu and Chester Kwak and Pallavi LV and Sarmishta Velury and Himadri Choudhury and Jamie Hall and Premal Shah and Ricardo Figueira and Matt Thomas and Minjie Lu and Ting Zhou and Chintu Kumar and Thomas Jurdi and Sharat Chikkerur and Yenai Ma and Adams Yu and Soo Kwak and Victor Ähdel and Sujeevan Rajayogam and Travis Choma and Fei Liu and Aditya Barua and Colin Ji and Ji Ho Park and Vincent Hellendoorn and Alex Bailey and Taylan Bilal and Huanjie Zhou and Mehrdad Khatir and Charles Sutton and Wojciech Rzadkowski and Fiona Macintosh and Konstantin Shagin and Paul Medina and Chen Liang and Jinjing Zhou and Pararth Shah and Yingying Bi and Attila Dankovics and Shipra Banga and Sabine Lehmann and Marissa Bredesen and Zifan Lin and John Eric Hoffmann and Jonathan Lai and Raynald Chung and Kai Yang and Nihal Balani and Arthur Bražinskas and Andrei Sozanschi and Matthew Hayes and Héctor Fernández Alcalde and Peter Makarov and Will Chen and Antonio Stella and Liselotte Snijders and Michael Mandl and Ante Kärrman and Paweł Nowak and Xinyi Wu and Alex Dyck and Krishnan Vaidyanathan and Raghavender R and Jessica Mallet and Mitch Rudominer and Eric Johnston and Sushil Mittal and Akhil Udathu and Janara Christensen and Vishal Verma and Zach Irving and Andreas Santucci and Gamaleldin Elsayed and Elnaz Davoodi and Marin Georgiev and Ian Tenney and Nan Hua and Geoffrey Cideron and Edouard Leurent and Mahmoud Alnahlawi and Ionut Georgescu and Nan Wei and Ivy Zheng and Dylan Scandinaro and Heinrich Jiang and Jasper Snoek and Mukund Sundararajan and Xuezhi Wang and Zack Ontiveros and Itay Karo and Jeremy Cole and Vinu Rajashekhar and Lara Tumeh and Eyal Ben-David and Rishub Jain and Jonathan Uesato and Romina Datta and Oskar Bunyan and Shimu Wu and John Zhang and Piotr Stanczyk and Ye Zhang and David Steiner and Subhajit Naskar and Michael Azzam and Matthew Johnson and Adam Paszke and Chung-Cheng Chiu and Jaume Sanchez Elias and Afroz Mohiuddin and Faizan Muhammad and Jin Miao and Andrew Lee and Nino Vieillard and Jane Park and Jiageng Zhang and Jeff Stanway and Drew Garmon and Abhijit Karmarkar and Zhe Dong and Jong Lee and Aviral Kumar and Luowei Zhou and Jonathan Evens and William Isaac and Geoffrey Irving and Edward Loper and Michael Fink and Isha Arkatkar and Nanxin Chen and Izhak Shafran and Ivan Petrychenko and Zhe Chen and Johnson Jia and Anselm Levskaya and Zhenkai Zhu and Peter Grabowski and Yu Mao and Alberto Magni and Kaisheng Yao and Javier Snaider and Norman Casagrande and Evan Palmer and Paul Suganthan and Alfonso Castaño and Irene Giannoumis and Wooyeol Kim and Mikołaj Rybiński and Ashwin Sreevatsa and Jennifer Prendki and David Soergel and Adrian Goedeckemeyer and Willi Gierke and Mohsen Jafari and Meenu Gaba and Jeremy Wiesner and Diana Gage Wright and Yawen Wei and Harsha Vashisht and Yana Kulizhskaya and Jay Hoover and Maigo Le and Lu Li and Chimezie Iwuanyanwu and Lu Liu and Kevin Ramirez and Andrey Khorlin and Albert Cui and Tian LIN and Marcus Wu and Ricardo Aguilar and Keith Pallo and Abhishek Chakladar and Ginger Perng and Elena Allica Abellan and Mingyang Zhang and Ishita Dasgupta and Nate Kushman and Ivo Penchev and Alena Repina and Xihui Wu and Tom van der Weide and Priya Ponnapalli and Caroline Kaplan and Jiri Simsa and Shuangfeng Li and Olivier Dousse and Fan Yang and Jeff Piper and Nathan Ie and Rama Pasumarthi and Nathan Lintz and Anitha Vijayakumar and Daniel Andor and Pedro Valenzuela and Minnie Lui and Cosmin Paduraru and Daiyi Peng and Katherine Lee and Shuyuan Zhang and Somer Greene and Duc Dung Nguyen and Paula Kurylowicz and Cassidy Hardin and Lucas Dixon and Lili Janzer and Kiam Choo and Ziqiang Feng and Biao Zhang and Achintya Singhal and Dayou Du and Dan McKinnon and Natasha Antropova and Tolga Bolukbasi and Orgad Keller and David Reid and Daniel Finchelstein and Maria Abi Raad and Remi Crocker and Peter Hawkins and Robert Dadashi and Colin Gaffney and Ken Franko and Anna Bulanova and Rémi Leblond and Shirley Chung and Harry Askham and Luis C. Cobo and Kelvin Xu and Felix Fischer and Jun Xu and Christina Sorokin and Chris Alberti and Chu-Cheng Lin and Colin Evans and Alek Dimitriev and Hannah Forbes and Dylan Banarse and Zora Tung and Mark Omernick and Colton Bishop and Rachel Sterneck and Rohan Jain and Jiawei Xia and Ehsan Amid and Francesco Piccinno and Xingyu Wang and Praseem Banzal and Daniel J. Mankowitz and Alex Polozov and Victoria Krakovna and Sasha Brown and MohammadHossein Bateni and Dennis Duan and Vlad Firoiu and Meghana Thotakuri and Tom Natan and Matthieu Geist and Ser tan Girgin and Hui Li and Jiayu Ye and Ofir Roval and Reiko Tojo and Michael Kwong and James Lee-Thorp and Christopher Yew and Danila Sinopalnikov and Sabela Ramos and John Mellor and Abhishek Sharma and Kathy Wu and David Miller and Nicolas Sonnerat and Denis Vnukov and Rory Greig and Jennifer Beattie and Emily Caveness and Libin Bai and Julian Eisenschlos and Alex Korchemniy and Tomy Tsai and Mimi Jasarevic and Weize Kong and Phuong Dao and Zeyu Zheng and Frederick Liu and Fan Yang and Rui Zhu and Tian Huey Teh and Jason Sanmiya and Evgeny Gladchenko and Nejc Trdin and Daniel Toyama and Evan Rosen and Sasan Tavakkol and Linting Xue and Chen Elkind and Oliver Woodman and John Carpenter and George Papamakarios and Rupert Kemp and Sushant Kafle and Tanya Grunina and Rishika Sinha and Alice Talbert and Diane Wu and Denese Owusu-Afriyie and Cosmo Du and Chloe Thornton and Jordi Pont-Tuset and Pradyumna Narayana and Jing Li and Saaber Fatehi and John Wieting and Omar Ajmeri and Benigno Uria and Yeongil Ko and Laura Knight and Amélie Héliou and Ning Niu and Shane Gu and Chenxi Pang and Yeqing Li and Nir Levine and Ariel Stolovich and Rebeca Santamaria-Fernandez and Sonam Goenka and Wenny Yustalim and Robin Strudel and Ali Elqursh and Charlie Deck and Hyo Lee and Zonglin Li and Kyle Levin and Raphael Hoffmann and Dan Holtmann-Rice and Olivier Bachem and Sho Arora and Christy Koh and Soheil Hassas Yeganeh and Siim Põder and Mukarram Tariq and Yanhua Sun and Lucian Ionita and Mojtaba Seyedhosseini and Pouya Tafti and Zhiyu Liu and Anmol Gulati and Jasmine Liu and Xinyu Ye and Bart Chrzaszcz and Lily Wang and Nikhil Sethi and Tianrun Li and Ben Brown and Shreya Singh and Wei Fan and Aaron Parisi and Joe Stanton and Vinod Koverkathu and Christopher A. Choquette-Choo and Yunjie Li and TJ Lu and Abe Ittycheriah and Prakash Shroff and Mani Varadarajan and Sanaz Bahargam and Rob Willoughby and David Gaddy and Guillaume Desjardins and Marco Cornero and Brona Robenek and Bhavishya Mittal and Ben Albrecht and Ashish Shenoy and Fedor Moiseev and Henrik Jacobsson and Alireza Ghaffarkhah and Morgane Rivière and Alanna Walton and Clément Crepy and Alicia Parrish and Zongwei Zhou and Clement Farabet and Carey Radebaugh and Praveen Srinivasan and Claudia van der Salm and Andreas Fidjeland and Salvatore Scellato and Eri Latorre-Chimoto and Hanna Klimczak-Plucińska and David Bridson and Dario de Cesare and Tom Hudson and Piermaria Mendolicchio and Lexi Walker and Alex Morris and Matthew Mauger and Alexey Guseynov and Alison Reid and Seth Odoom and Lucia Loher and Victor Cotruta and Madhavi Yenugula and Dominik Grewe and Anastasia Petrushkina and Tom Duerig and Antonio Sanchez and Steve Yadlowsky and Amy Shen and Amir Globerson and Lynette Webb and Sahil Dua and Dong Li and Surya Bhupatiraju and Dan Hurt and Haroon Qureshi and Ananth Agarwal and Tomer Shani and Matan Eyal and Anuj Khare and Shreyas Rammohan Belle and Lei Wang and Chetan Tekur and Mihir Sanjay Kale and Jinliang Wei and Ruoxin Sang and Brennan Saeta and Tyler Liechty and Yi Sun and Yao Zhao and Stephan Lee and Pandu Nayak and Doug Fritz and Manish Reddy Vuyyuru and John Aslanides and Nidhi Vyas and Martin Wicke and Xiao Ma and Evgenii Eltyshev and Nina Martin and Hardie Cate and James Manyika and Keyvan Amiri and Yelin Kim and Xi Xiong and Kai Kang and Florian Luisier and Nilesh Tripuraneni and David Madras and Mandy Guo and Austin Waters and Oliver Wang and Joshua Ainslie and Jason Baldridge and Han Zhang and Garima Pruthi and Jakob Bauer and Feng Yang and Riham Mansour and Jason Gelman and Yang Xu and George Polovets and Ji Liu and Honglong Cai and Warren Chen and XiangHai Sheng and Emily Xue and Sherjil Ozair and Christof Angermueller and Xiaowei Li and Anoop Sinha and Weiren Wang and Julia Wiesinger and Emmanouil Koukoumidis and Yuan Tian and Anand Iyer and Madhu Gurumurthy and Mark Goldenson and Parashar Shah and MK Blake and Hongkun Yu and Anthony Urbanowicz and Jennimaria Palomaki and Chrisantha Fernando and Ken Durden and Harsh Mehta and Nikola Momchev and Elahe Rahimtoroghi and Maria Georgaki and Amit Raul and Sebastian Ruder and Morgan Redshaw and Jinhyuk Lee and Denny Zhou and Komal Jalan and Dinghua Li and Blake Hechtman and Parker Schuh and Milad Nasr and Kieran Milan and Vladimir Mikulik and Juliana Franco and Tim Green and Nam Nguyen and Joe Kelley and Aroma Mahendru and Andrea Hu and Joshua Howland and Ben Vargas and Jeffrey Hui and Kshitij Bansal and Vikram Rao and Rakesh Ghiya and Emma Wang and Ke Ye and Jean Michel Sarr and Melanie Moranski Preston and Madeleine Elish and Steve Li and Aakash Kaku and Jigar Gupta and Ice Pasupat and Da-Cheng Juan and Milan Someswar and Tejvi M. and Xinyun Chen and Aida Amini and Alex Fabrikant and Eric Chu and Xuanyi Dong and Amruta Muthal and Senaka Buthpitiya and Sarthak Jauhari and Nan Hua and Urvashi Khandelwal and Ayal Hitron and Jie Ren and Larissa Rinaldi and Shahar Drath and Avigail Dabush and Nan-Jiang Jiang and Harshal Godhia and Uli Sachs and Anthony Chen and Yicheng Fan and Hagai Taitelbaum and Hila Noga and Zhuyun Dai and James Wang and Chen Liang and Jenny Hamer and Chun-Sung Ferng and Chenel Elkind and Aviel Atias and Paulina Lee and Vít Listík and Mathias Carlen and Jan van de Kerkhof and Marcin Pikus and Krunoslav Zaher and Paul Müller and Sasha Zykova and Richard Stefanec and Vitaly Gatsko and Christoph Hirnschall and Ashwin Sethi and Xingyu Federico Xu and Chetan Ahuja and Beth Tsai and Anca Stefanoiu and Bo Feng and Keshav Dhandhania and Manish Katyal and Akshay Gupta and Atharva Parulekar and Divya Pitta and Jing Zhao and Vivaan Bhatia and Yashodha Bhavnani and Omar Alhadlaq and Xiaolin Li and Peter Danenberg and Dennis Tu and Alex Pine and Vera Filippova and Abhipso Ghosh and Ben Limonchik and Bhargava Urala and Chaitanya Krishna Lanka and Derik Clive and Yi Sun and Edward Li and Hao Wu and Kevin Hongtongsak and Ianna Li and Kalind Thakkar and Kuanysh Omarov and Kushal Majmundar and Michael Alverson and Michael Kucharski and Mohak Patel and Mudit Jain and Maksim Zabelin and Paolo Pelagatti and Rohan Kohli and Saurabh Kumar and Joseph Kim and Swetha Sankar and Vineet Shah and Lakshmi Ramachandruni and Xiangkai Zeng and Ben Bariach and Laura Weidinger and Tu Vu and Alek Andreev and Antoine He and Kevin Hui and Sheleem Kashem and Amar Subramanya and Sissie Hsiao and Demis Hassabis and Koray Kavukcuoglu and Adam Sadovsky and Quoc Le and Trevor Strohman and Yonghui Wu and Slav Petrov and Jeffrey Dean and Oriol Vinyals},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.11805}, 
}

@preprint{LLM2CLIP,
      title={LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation}, 
      author={Weiquan Huang and Aoqi Wu and Yifan Yang and Xufang Luo and Yuqing Yang and Liang Hu and Qi Dai and Xiyang Dai and Dongdong Chen and Chong Luo and Lili Qiu},
      year={2024},
      eprint={2411.04997},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.04997}, 
}

@article{datacomp,
 author = {Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and Orgad, Eyal and Entezari, Rahim and Daras, Giannis and Pratt, Sarah and Ramanujan, Vivek and Bitton, Yonatan and Marathe, Kalyani and Mussmann, Stephen and Vencu, Richard and Cherti, Mehdi and Krishna, Ranjay and Koh, Pang Wei W and Saukh, Olga and Ratner, Alexander J and Song, Shuran and Hajishirzi, Hannaneh and Farhadi, Ali and Beaumont, Romain and Oh, Sewoong and Dimakis, Alex and Jitsev, Jenia and Carmon, Yair and Shankar, Vaishaal and Schmidt, Ludwig},
 journal = {Advances in Neural Information Processing Systems},
 title = {DataComp: In search of the next generation of multimodal datasets},
 volume = {36},
 year = {2023}
}

@article{kim2018paraphrasing,
  title={Paraphrasing complex network: Network compression via factor transfer},
  author={Kim, Jangho and Park, SeongUk and Kwak, Nojun},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{super-resolution,
  title={Deep learning for image super-resolution: A survey},
  author={Wang, Zhihao and Chen, Jian and Hoi, Steven CH},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={43},
  number={10},
  pages={3365--3387},
  year={2020},
  publisher={IEEE}
}

@misc{genie2,
  title         = {Genie 2: A Large-Scale Foundation World Model},
  author        = {Jack Parker-Holder and Philip Ball and Jake Bruce and Vibhavari Dasagi and Kristian Holsheimer and Christos Kaplanis and Alexandre Moufarek and Guy Scully and Jeremy Shar and Jimmy Shi and Stephen Spencer and Jessica Yung and Michael Dennis and Sultan Kenjeyev and Shangbang Long and Vlad Mnih and Harris Chan and Maxime Gazeau and Bonnie Li and Fabio Pardo and Luyu Wang and Lei Zhang and Frederic Besse and Tim Harley and Anna Mitenkova and Jane Wang and Jeff Clune and Demis Hassabis and Raia Hadsell and Adrian Bolton and Satinder Singh and Tim Rockt{\"a}schel},
  year          = {2024},
  howpublished={\url{https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model}},
}

@misc{veo2,
  title={Veo 2},
  author={Veo-Team and Agrim Gupta and Ali Razavi and Andeep Toor and Ankush Gupta and Dumitru Erhan and Eleni Shaw and Eric Lau and Frank Belletti and Gabe Barth-Maron and Gregory Shaw and Hakan Erdogan and Hakim Sidahmed and Henna Nandwani and Hernan Moraldo and Hyunjik Kim and Irina Blok and Jeff Donahue and José Lezama and Kory Mathewson and Kurtis David and Matthieu Kim Lorrain and Marc van Zee and Medhini Narasimhan and Miaosen Wang and Mohammad Babaeizadeh and Nelly Papalampidi and Nick Pezzotti and Nilpa Jha and Parker Barnes and Pieter-Jan Kindermans and Rachel Hornung and Ruben Villegas and Ryan Poplin and Salah Zaiem and Sander Dieleman and Sayna Ebrahimi and Scott Wisdom and Serena Zhang and Shlomi Fruchter and Signe Nørly and Weizhe Hua and Xinchen Yan and Yuqing Du and Yutian Chen},
  howpublished={\url{https://deepmind.google/technologies/veo/veo-2}},
  year={2024}
}

@inproceedings{adaln,
author = { Chen, Qifeng and Xu, Jia and Koltun, Vladlen },
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
title = {Fast Image Processing with Fully-Convolutional Networks},
year = {2017},
pages = {2516-2525},
}

@article{gan,
 author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 journal = {Advances in Neural Information Processing Systems},
 title = {Generative Adversarial Nets},
 volume = {27},
 year = {2014}
}


@article{maskformer,
 author = {Cheng, Bowen and Schwing, Alex and Kirillov, Alexander},
 journal = {Advances in Neural Information Processing Systems},
 title = {Per-Pixel Classification is Not All You Need for Semantic Segmentation},
 volume = {34},
 year = {2021}
}

@InProceedings{liu2022video,
    author    = {Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
    title     = {Video Swin Transformer},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {3202-3211}
}

@InProceedings{unicl,
    author    = {Yang, Jianwei and Li, Chunyuan and Zhang, Pengchuan and Xiao, Bin and Liu, Ce and Yuan, Lu and Gao, Jianfeng},
    title     = {Unified Contrastive Learning in Image-Text-Label Space},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {19163-19173}
}

@article{NEURIPS2024_2a952768,
 author = {YANG, CHENYU and Zhu, Xizhou and Zhu, Jinguo and Su, Weijie and Wang, Junjie and Dong, Xuan and Wang, Wenhai and Li, Bin and Zhou, Jie and Qiao, Yu and Dai, Jifeng},
 journal = {Advances in Neural Information Processing Systems},
 title = {Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning},
 volume = {37},
 year = {2024}
}


@inproceedings{layoutlm,
author = {Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
title = {LayoutLM: Pre-training of Text and Layout for Document Image Understanding},
year = {2020},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {1192–1200},
}

@preprint{DomLM,
      title={DOM-LM: Learning Generalizable Representations for HTML Documents}, 
      author={Xiang Deng and Prashant Shiralkar and Colin Lockard and Binxuan Huang and Huan Sun},
      year={2022},
      eprint={2201.10608},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.10608}, 
}

@InProceedings{CLIPPO,
    author    = {Tschannen, Michael and Mustafa, Basil and Houlsby, Neil},
    title     = {CLIPPO: Image-and-Language Understanding From Pixels Only},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2023},
    pages     = {11006-11017}
}

@InProceedings{cc,
  author       = "Gong, Xian and Mccarthy, Paul X. and Rizoiu, Marian-Andrei and Boldi, Paolo",
  title        = "Harmony in the Australian Domain Space",
  year         = "2024",
  booktitle    = "Proceedings of the 16th ACM Web Science Conference",
  pages        = "92--102",
}

@preprint{pile,
      title={The Pile: An 800GB Dataset of Diverse Text for Language Modeling}, 
      author={Leo Gao and Stella Biderman and Sid Black and Laurence Golding and Travis Hoppe and Charles Foster and Jason Phang and Horace He and Anish Thite and Noa Nabeshima and Shawn Presser and Connor Leahy},
      year={2020},
      eprint={2101.00027},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2101.00027}, 
}

@preprint{genex,
      title={GenEx: Generating an Explorable World}, 
      author={Taiming Lu and Tianmin Shu and Junfei Xiao and Luoxin Ye and Jiahao Wang and Cheng Peng and Chen Wei and Daniel Khashabi and Rama Chellappa and Alan Yuille and Jieneng Chen},
      year={2025},
      eprint={2412.09624},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.09624}, 
}

@InProceedings{LEMON,
    author    = {Hu, Xiaowei and Gan, Zhe and Wang, Jianfeng and Yang, Zhengyuan and Liu, Zicheng and Lu, Yumao and Wang, Lijuan},
    title     = {Scaling Up Vision-Language Pre-Training for Image Captioning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {17980-17989}
}

@article{embodiment,
title = {Cognition as a dynamic system: Principles from embodiment},
journal = {Developmental Review},
volume = {25},
number = {3},
pages = {278-298},
year = {2005},
note = {Development as Self-organization: New Approaches to the Psychology and Neurobiology of Development},
issn = {0273-2297},
doi = {https://doi.org/10.1016/j.dr.2005.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0273229705000304},
author = {Linda B. Smith},
keywords = {Dynamic systems, Cognition, Concepts, Development},
abstract = {Traditional approaches to cognitive development concentrate on the stability of cognition and explain that stability via concepts segregated from perceiving acting. A dynamic systems approach in contrast focuses on the self-organization of behavior in tasks. This article uses recent results concerning the embodiment of cognition to argue for a dynamic systems approach. The embodiment hypothesis is the idea that intelligence emerges in the interaction of an organism with an environment and as a result of sensory-motor activity. The continual coupling of cognition to the world through the body both adapts cognition to the idiosyncrasies of the here and now, makes it relevant, and provides the mechanism for developmental change.}
}

@book{understand,
  title={Understanding intelligence},
  author={Pfeifer, Rolf and Scheier, Christian},
  year={2001},
  publisher={MIT press}
}

@inproceedings{gpt3,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@ARTICLE{brnn,
  author={Schuster, M. and Paliwal, K.K.},
  journal={IEEE Transactions on Signal Processing}, 
  title={Bidirectional recurrent neural networks}, 
  year={1997},
  volume={45},
  number={11},
  pages={2673-2681},
  keywords={Recurrent neural networks;Artificial neural networks;Training data;Databases;Probability;Shape;Parameter estimation;Speech recognition;Control systems;Telecommunication control},
  doi={10.1109/78.650093}}


@ARTICLE{lenet,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi={10.1109/5.726791}}

@preprint{wang2020minivlm,
      title={MiniVLM: A Smaller and Faster Vision-Language Model}, 
      author={Jianfeng Wang and Xiaowei Hu and Pengchuan Zhang and Xiujun Li and Lijuan Wang and Lei Zhang and Jianfeng Gao and Zicheng Liu},
      year={2021},
      eprint={2012.06946},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2012.06946}, 
}

@inproceedings{fang2021compressing,
  title={Compressing visual-linguistic model via knowledge distillation},
  author={Fang, Zhiyuan and Wang, Jianfeng and Hu, Xiaowei and Wang, Lijuan and Yang, Yezhou and Liu, Zicheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1428--1438},
  year={2021}
}

@preprint{gao2019masked,
      title={Masked Non-Autoregressive Image Captioning}, 
      author={Junlong Gao and Xi Meng and Shiqi Wang and Xia Li and Shanshe Wang and Siwei Ma and Wen Gao},
      year={2019},
      eprint={1906.00717},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1906.00717}, 
}


@inproceedings{guo2020non,
  title     = {Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning},
  author    = {Guo, Longteng and Liu, Jing and Zhu, Xinxin and He, Xingjian and Jiang, Jie and Lu, Hanqing},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
  pages     = {767--773},
  year      = {2020},
}


@preprint{fei2019fast,
      title={Fast Image Caption Generation with Position Alignment}, 
      author={Zhengcong Fei},
      year={2019},
      eprint={1912.06365},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1912.06365}, 
}

@inproceedings{zhou2020unified,
  title={Unified vision-language pre-training for image captioning and vqa},
  author={Zhou, Luowei and Palangi, Hamid and Zhang, Lei and Hu, Houdong and Corso, Jason and Gao, Jianfeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={13041--13049},
  year={2020}
}

@inproceedings{UNIMO,
    title = "{UNIMO}: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning",
    author = "Li, Wei  and
      Gao, Can  and
      Niu, Guocheng  and
      Xiao, Xinyan  and
      Liu, Hao  and
      Liu, Jiachen  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    publisher = "Association for Computational Linguistics",
    pages = "2592--2607",
}

@inproceedings{bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    publisher = "Association for Computational Linguistics",
    month = jul,
    year = "2002",
    pages = "311--318"
}

@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    publisher = "Association for Computational Linguistics",
    pages = "74--81"
}

@inproceedings{meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    publisher = "Association for Computational Linguistics",
    pages = "65--72"
}

@inproceedings{spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
    booktitle = {Proceedings of the European Conference on Computer Vision},
    organization = {Springer},
  pages={382--398},
  year={2016},
}

@inproceedings{chaudhry2018riemannian,
  title={Riemannian walk for incremental learning: Understanding forgetting and intransigence},
  author={Chaudhry, Arslan and Dokania, Puneet K and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={532--547},
    organization = {Springer},
  year={2018}
}

@inproceedings{vinyals2015show,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3156--3164},
  year={2015}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3128--3137},
  year={2015}
}

@preprint{dall-e2,
      title={Hierarchical Text-Conditional Image Generation with CLIP Latents}, 
      author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
      year={2022},
      eprint={2204.06125},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.06125}, 
}

@InProceedings{densecap,
  title={DenseCap: Fully Convolutional Localization Networks for Dense Captioning},
  author={Johnson, Justin and Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and 
             Pattern Recognition},
  year={2016},
  pages     = {4565-4574}
}

@InProceedings{latentdiff,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {10684-10695}
}

@InProceedings{glide,
  title = 	 {{GLIDE}: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
  author =       {Nichol, Alexander Quinn and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and Mcgrew, Bob and Sutskever, Ilya and Chen, Mark},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {16784--16804},
  year = 	 {2022},
  organization =    {PMLR},
}


@article{beatsgan,
 author = {Dhariwal, Prafulla and Nichol, Alexander},
 journal = {Advances in Neural Information Processing Systems},
 title = {Diffusion Models Beat GANs on Image Synthesis},
 volume = {34},
 year = {2021}
}


@inproceedings{
ddim,
title={Denoising Diffusion Implicit Models},
author={Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{ddpm,
author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
title = {Denoising diffusion probabilistic models},
year = {2020}, 
journal = {Advances in Neural Information Processing Systems},
volume = {33},
}


@inproceedings{touvron2022deit,
author = {Touvron, Hugo and Cord, Matthieu and J\'{e}gou, Herv\'{e}},
title = {DeiT III: Revenge of the ViT},
year = {2022},    
booktitle = {Proceedings of the European Conference on Computer Vision},
    organization = {Springer},
pages = {516–533},
}

@InProceedings{ftclip2021,
    author    = {Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
    title     = {Robust Fine-Tuning of Zero-Shot Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {7959-7971}
}

@preprint{siglip-2,
      title={SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features}, 
      author={Michael Tschannen and Alexey Gritsenko and Xiao Wang and Muhammad Ferjad Naeem and Ibrahim Alabdulmohsin and Nikhil Parthasarathy and Talfan Evans and Lucas Beyer and Ye Xia and Basil Mustafa and Olivier Hénaff and Jeremiah Harmsen and Andreas Steiner and Xiaohua Zhai},
      year={2025},
      eprint={2502.14786},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.14786}, 
}

@inproceedings{song-etal-2022-clip,
    title = "{CLIP} Models are Few-Shot Learners: Empirical Studies on {VQA} and Visual Entailment",
    author = "Song, Haoyu  and
      Dong, Li  and
      Zhang, Weinan  and
      Liu, Ting  and
      Wei, Furu",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    publisher = "Association for Computational Linguistics",
    pages = "6088--6100",
}

@inproceedings{shen2022how,
    title={How Much Can {CLIP} Benefit Vision-and-Language Tasks?},
    author={Sheng Shen and Liunian Harold Li and Hao Tan and Mohit Bansal and Anna Rohrbach and Kai-Wei Chang and Zhewei Yao and Kurt Keutzer},
    booktitle={International Conference on Learning Representations},
    year={2022},
}

@preprint{llavanextinterleave,
      title={LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models}, 
      author={Feng Li and Renrui Zhang and Hao Zhang and Yuanhan Zhang and Bo Li and Wei Li and Zejun Ma and Chunyuan Li},
      year={2024},
      eprint={2407.07895},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.07895}, 
}

@inproceedings{
minigpt4,
title={Mini{GPT}-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},
author={Deyao Zhu and Jun Chen and Xiaoqian Shen and Xiang Li and Mohamed Elhoseiny},
booktitle={International Conference on Learning Representations},
year={2024},
}

@InProceedings{cocoop,
    author    = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
    title     = {Conditional Prompt Learning for Vision-Language Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    month     = {June},
    year      = {2022},
    pages     = {16816-16825}
}

@article{coop,
author = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
title = {Learning to Prompt for Vision-Language Models},
year = {2022},
volume = {130},
journal={International Journal of Computer Vision},
publisher={Springer},
pages = {2337–2348},
}

@article{cae,
author = {Chen, Xiaokang and Ding, Mingyu and Wang, Xiaodi and Xin, Ying and Mo, Shentong and Wang, Yunhao and Han, Shumin and Luo, Ping and Zeng, Gang and Wang, Jingdong},
title = {Context Autoencoder for Self-supervised Representation Learning},
year = {2023},
volume = {132},
journal={International Journal of Computer Vision},
pages = {208–223},
}

@preprint{lars,
      title={Large Batch Training of Convolutional Networks}, 
      author={Yang You and Igor Gitman and Boris Ginsburg},
      year={2017},
      eprint={1708.03888},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1708.03888}, 
}

@inproceedings{adamw,
 author = {Loshchilov, Ilya and Hutter, Frank},
 booktitle = {International Conference on Learning Representations},
 title = {Decoupled Weight Decay Regularization},
 year = {2019}
}


@inproceedings{NYUv2,
 author = {Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
 booktitle = {Proceedings of the European Conference on Computer Vision},
 organization = {Springer},
 pages = {746--760},
 title = {Indoor Segmentation and Support Inference from RGBD Images},
 year = {2012}
}

@article{AMT,
author = {Buhrmester, Michael and Kwang, Tracy and Gosling, Samuel},
year = {2011},
month = {02},
pages = {3-5},
title = {Amazon's Mechanical Turk: A New Source of Inexpensive, Yet High-Quality, Data?},
volume = {6},
journal = {Perspectives on Psychological Science},
}

@inproceedings{
hjelm2018learning,
title={Learning deep representations by mutual information estimation and maximization},
author={R Devon Hjelm and Alex Fedorov and Samuel Lavoie-Marchildon and Karan Grewal and Phil Bachman and Adam Trischler and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2019},
}

%
%  title={Microsoft coco captions: Data collection and evaluation server},
%  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
%  journal={arXiv preprint arXiv:1504.00325},
%  year={2015}
%}

@inproceedings{chen2015microsoft,
 author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
 booktitle = {Proceedings of the European Conference on Computer Vision},
 organization = {Springer},
 pages = {740--755},
 title = {Microsoft COCO: Common Objects in Context},
 year = {2014}
}

@article{Transformer,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
 journal = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@article{HinSal06, 
  author =	"Geoffrey Hinton and Ruslan Salakhutdinov", 
  title =	"Reducing the Dimensionality of Data with Neural 
		 Networks",  
  journal =	"Science", 
  volume =	"313", 
  number =      "5786",
  pages =       "504 - 507",
  year = 	"2006",  
}

@article{alexnet,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
journal = {Advances in Neural Information Processing Systems},
volume = {25},
year = {2012}
}


@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9653--9663},
  year={2022}
}

@inproceedings{furlanello2018born,
  title={Born again neural networks},
  author={Furlanello, Tommaso and Lipton, Zachary and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  booktitle={Proceedings of the 35th International Conference on Machine Learning},
  pages={1607--1616},
  year={2018},
  organization={PMLR}
}

@article{wang2020minilm,
  title={Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers},
  author={Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{bao2021beit,
  title={BEiT: BERT Pre-Training of Image Transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{goh2021multimodal,
  title={Multimodal neurons in artificial neural networks},
  author={Goh, Gabriel and Cammarata, Nick and Voss, Chelsea and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris},
  journal={Distill},
  year={2021}
}

@inproceedings{dosovitskiy2020vit,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
 journal = {Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{xie2023revealing,
  title={Revealing the dark secrets of masked image modeling},
  author={Xie, Zhenda and Geng, Zigang and Hu, Jingcheng and Zhang, Zheng and Hu, Han and Cao, Yue},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14475--14485},
  year={2023}
}

@preprint{zhou2021deepvit,
      title={DeepViT: Towards Deeper Vision Transformer}, 
      author={Daquan Zhou and Bingyi Kang and Xiaojie Jin and Linjie Yang and Xiaochen Lian and Zihang Jiang and Qibin Hou and Jiashi Feng},
      year={2021},
      eprint={2103.11886},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.11886}, 
}

@inproceedings{li2022mvitv2,
  title={Mvitv2: Improved multiscale vision transformers for classification and detection},
  author={Li, Yanghao and Wu, Chao-Yuan and Fan, Haoqi and Mangalam, Karttikeya and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4804--4814},
  year={2022}
}

@misc{ba2016layer,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1607.06450}, 
}

@article{ren2016faster,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 journal = {Advances in Neural Information Processing Systems},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 volume = {28},
 year = {2015}
}

@inproceedings{dino,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{huang2019attention,
  title={Attention on attention for image captioning},
  author={Huang, Lun and Wang, Wenmin and Chen, Jie and Wei, Xiao-Yong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4633--4642},
  year={2019}
}

@inproceedings{deit,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={Proceedings of the 38th International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@inproceedings{kornblith2019similarity,
  title={Similarity of neural network representations revisited},
  author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle={Proceedings of the 36th International Conference on Machine Learning},
  pages={3519--3529},
  year={2019},
  organization={PMLR}
}

@preprint{hinton2015knowledge,
  author    = {Geoffrey E. Hinton and
               Oriol Vinyals and
               Jeffrey Dean},
  title     = {Distilling the Knowledge in a Neural Network},
  eprint    = {1503.02531},
  year      = {2015},
          archiveprefix={arXiv},
          url={https://arxiv.org/abs/1503.02531}
}

@inproceedings{rcnn13,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={580--587},
  year={2014}
}

@inproceedings{lu2017knowing,
  title={Knowing when to look: Adaptive attention via a visual sentinel for image captioning},
  author={Lu, Jiasen and Xiong, Caiming and Parikh, Devi and Socher, Richard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3242--3250},
  year={2017}
}

@inproceedings{long2015fully,
 author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
 booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
 pages = {3431--3440},
 title = {Fully Convolutional Networks for Semantic Segmentation},
 year = {2015}
}

@inproceedings{openclip,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2818--2829},
  year={2023}
}

@article{young2014flickr,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press}
}


@preprint{kaplan2020scaling,
  title={Scaling Laws for Neural Language Models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  eprint={2001.08361},
  archiveprefix={arXiv},
  url={https://arxiv.org/abs/2001.08361},
  year={2020}
}

@inproceedings{aghajanyan2023scaling,
  title={Scaling laws for generative mixed-modal language models},
  author={Aghajanyan, Armen and Yu, Lili and Conneau, Alexis and Hsu, Wei-Ning and Hambardzumyan, Karen and Zhang, Susan and Roller, Stephen and Goyal, Naman and Levy, Omer and Zettlemoyer, Luke},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={265--279},
  year={2023},
  organization={PMLR}
}

@preprint{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  eprint={2010.14701},
  archiveprefix={arXiv},
  url={https://arxiv.org/abs/2010.14701},
  year={2020}
}

@inproceedings{xie2023data,
  title={On data scaling in masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Wei, Yixuan and Dai, Qi and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10365--10374},
  year={2023}
}

@inproceedings{xie2021propagate,
  title={Propagate yourself: Exploring pixel-level consistency for unsupervised visual representation learning},
  author={Xie, Zhenda and Lin, Yutong and Zhang, Zheng and Cao, Yue and Lin, Stephen and Hu, Han},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16684--16693},
  year={2021}
}

@inproceedings{baevski2022data2vec,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  booktitle={Proceedings of the 39th International Conference on Machine Learning},
  pages={1298--1312},
  year={2022},
  organization={PMLR}
}
