% !TeX root = ../main.tex

\begin{comments}
% \begin{comments}[name = {指导小组评语}]
% \begin{comments}[name = {Comments from Thesis Supervisor}]
% \begin{comments}[name = {Comments from Thesis Supervision Committee}]

  % 论文提出了……
语言-图像对比学习（CLIP）方法借助语言模态在语义表达上的优势，解决了已有的视觉预训练方法无法建模语义概念或语义空间封闭的问题。然而CLIP方法在预训练和迁移阶段面临重大挑战。韦毅轩同学的论文围绕CLIP方法在预训练数据构建、细粒度视觉任务迁移和语义生成任务迁移等核心难点展开深入探索。论文成果具有重要的理论和实用价值。该论文的主要创新结果为：

\begin{enumerate}
    \item 深入研究了CLIP方法预训练数据中的语义噪声问题，提出了基于高质量图像分类数据扩展的预训练方法。该方法通过从对比学习的视角重新理解图像分类任务，因此使得CLIP方法可以利用语义噪声较低的图像分类数据进行增强；并引入外部专家知识库增强图像类别的语义信息，扩充了各类别知识的丰富程度。该方法增强了CLIP方法对齐视觉与语言表征的效果，提升了CLIP方法在图文跨模态检索和开放集合图像识别等任务上的表现。
    \item 针对CLIP方法在依赖密集预测能力的细粒度视觉任务迁移表现不佳的问题，提出了基于特征图自蒸馏增强的方法，充分利用CLIP方法视觉表征中蕴含的语义信息。该方法通过与像素级自监督预训练方法进行对比分析，揭示了像素级训练目标的重要性。该方法利用模型自蒸馏的方式，在无需额外数据标注的情况下构建了细粒度训练目标，并有效改善了CLIP方法在语义分割、深度估计等视觉任务上的性能。
    \item CLIP方法通过判别式训练实现视觉和语言表征的有效对齐，但无法直接用于语义生成任务。针对这一问题，提出了基于离散扩散模型的语义生成任务的迁移方法。该方法针对文本信号的离散性、低冗余性和长度可变特性对离散扩散模型进行改进，首次在图像描述生成的迁移任务上取得与发展成熟的自回归方法相当的性能，并在图像描述修改任务上表现更佳，为后续提升CLIP方法语义生成速度开辟了新途径。
\end{enumerate}

论文由韦毅轩同学在导师和合作老师的指导下独立完成，围绕CLIP在预训练和迁移阶段的挑战进行了具有创新性和实用性的研究。论文整体书写规范，参考文献详尽，逻辑清晰明确，实验设计充分，是一篇优秀的博士学位论文。

\end{comments}
